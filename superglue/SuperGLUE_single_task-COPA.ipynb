{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from parse_COPA import get_COPA_dataloaders\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-28 02:36:05,843][INFO] emmental.meta:95 - Setting logging directory to: logs/2019_05_28/02_36_05\n",
      "[2019-05-28 02:36:05,860][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch1/senwu/mmtl/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-05-28 02:36:05,861][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 1, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 10,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"lr_scheduler_config\": {\n",
    "                \"warmup_percentage\": 0.1,\n",
    "                \"lr_scheduler\": None, #\"linear\",\n",
    "#                 \"min_lr\": 1e-7,\n",
    "            },\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 100,\n",
    "            \"checkpointing\": None,\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta_config': {'seed': 0, 'verbose': True, 'log_path': None},\n",
       " 'model_config': {'model_path': None, 'device': 1, 'dataparallel': False},\n",
       " 'learner_config': {'fp16': False,\n",
       "  'n_epochs': 10,\n",
       "  'train_split': 'train',\n",
       "  'valid_split': 'val',\n",
       "  'test_split': 'test',\n",
       "  'ignore_index': -100,\n",
       "  'optimizer_config': {'optimizer': 'adam',\n",
       "   'lr': 1e-05,\n",
       "   'l2': 0.0,\n",
       "   'grad_clip': 1.0,\n",
       "   'sgd_config': {'momentum': 0.9},\n",
       "   'adam_config': {'betas': (0.9, 0.999)}},\n",
       "  'lr_scheduler_config': {'lr_scheduler': None,\n",
       "   'warmup_steps': None,\n",
       "   'warmup_unit': 'batch',\n",
       "   'warmup_percentage': 0.1,\n",
       "   'min_lr': 0.0,\n",
       "   'linear_config': {'min_lr': 0.0},\n",
       "   'exponential_config': {'gamma': 0.9},\n",
       "   'plateau_config': {'factor': 0.5, 'patience': 10, 'threshold': 0.0001}},\n",
       "  'task_scheduler': 'round_robin',\n",
       "  'global_evaluation_metric_dict': None},\n",
       " 'logging_config': {'counter_unit': 'batch',\n",
       "  'evaluation_freq': 100,\n",
       "  'writer_config': {'writer': 'tensorboard', 'verbose': True},\n",
       "  'checkpointing': None,\n",
       "  'checkpointer_config': {'checkpoint_path': None,\n",
       "   'checkpoint_freq': 1,\n",
       "   'checkpoint_metric': None,\n",
       "   'checkpoint_task_metrics': None,\n",
       "   'checkpoint_runway': 0,\n",
       "   'checkpoint_clear': True}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"COPA\"\n",
    "DATA_DIR = \"data\"\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-28 02:36:05,997][INFO] tokenizer:8 - Loading Tokenizer bert-large-cased\n",
      "[2019-05-28 02:36:06,270][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/COPA/train.jsonl\n",
      "{'premise': 'My body cast a shadow over the grass.', 'choice1': 'The sun was rising.', 'choice2': 'The grass was cut.', 'question': 'cause', 'label': 0, 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-28 02:36:06,630][INFO] parse_COPA:123 - Loaded train for COPA.\n",
      "[2019-05-28 02:36:06,712][INFO] parse_COPA:123 - Loaded val for COPA.\n",
      "[2019-05-28 02:36:07,102][INFO] parse_COPA:123 - Loaded test for COPA.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 34\n",
      "data/COPA/val.jsonl\n",
      "{'premise': 'The man turned on the faucet.', 'choice1': 'The toilet filled with water.', 'choice2': 'Water flowed from the spout.', 'question': 'effect', 'label': 1, 'idx': 0}\n",
      "max len 34\n",
      "data/COPA/test.jsonl\n",
      "{'premise': 'The item was packaged in bubble wrap.', 'choice1': 'It was fragile.', 'choice2': 'It was small.', 'question': 'cause', 'idx': 0}\n",
      "max len 36\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_COPA_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\", \"test\"],\n",
    "    max_sequence_length=128,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(task_name, immediate_ouput_dict, Y, active):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(task_name, immediate_ouput_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChoiceModule(nn.Module):\n",
    "    def __init__(self, n_choices=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_choices = n_choices\n",
    "        self.linears = nn.ModuleDict(\n",
    "            {f\"linear{str(i)}\": nn.Linear(BERT_OUTPUT_DIM, 1) for i in range(n_choices)}\n",
    "        )\n",
    "\n",
    "    def forward(self, immediate_ouput_dict):\n",
    "        logits = []\n",
    "\n",
    "        for i in range(self.n_choices):\n",
    "            logit = self.linears[f\"linear{str(i)}\"].forward(\n",
    "                immediate_ouput_dict[f\"choice{str(i)}\"][0][-1][:,0,:]\n",
    "            )\n",
    "            logits.append(logit)\n",
    "\n",
    "        logits = torch.cat(logits, dim=1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ChoiceModule(nn.Module):\n",
    "#     def __init__(self, n_choices=2):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.n_choices = n_choices\n",
    "#         self.linear = nn.Linear(BERT_OUTPUT_DIM, 1)\n",
    "\n",
    "#     def forward(self, immediate_ouput_dict):\n",
    "#         logits = []\n",
    "\n",
    "#         for i in range(self.n_choices):\n",
    "#             logit = self.linear.forward(\n",
    "#                 immediate_ouput_dict[f\"choice{str(i)}\"][0][-1][:,0,:]\n",
    "#             )\n",
    "#             logits.append(logit)\n",
    "\n",
    "#         logits = torch.cat(logits, dim=1)\n",
    "\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-28 02:36:07,564][INFO] pytorch_pretrained_bert.modeling:580 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "[2019-05-28 02:36:07,566][INFO] pytorch_pretrained_bert.modeling:588 - extracting archive file ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmp6osx68u9\n",
      "[2019-05-28 02:36:24,890][INFO] pytorch_pretrained_bert.modeling:598 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[2019-05-28 02:36:56,040][INFO] emmental.task:34 - Created task: COPA\n"
     ]
    }
   ],
   "source": [
    "emmental_task = EmmentalTask(\n",
    "    name=TASK_NAME,\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "            f\"{TASK_NAME}_pred_head\": ChoiceModule(2),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": \"choice0\",\n",
    "            \"module\": \"bert_module\",\n",
    "            \"inputs\": [(\"_input_\", \"token1_ids\")],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"choice1\",\n",
    "            \"module\": \"bert_module\",\n",
    "            \"inputs\": [(\"_input_\", \"token2_ids\")],\n",
    "        },\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [],\n",
    "        },\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, TASK_NAME),\n",
    "    output_func=partial(output, TASK_NAME),\n",
    "    scorer=Scorer(\n",
    "        metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-28 02:36:56,092][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n",
      "[2019-05-28 02:37:01,999][INFO] emmental.model:44 - Created emmental model SuperGLUE_single_task that contains task {'COPA'}.\n",
      "[2019-05-28 02:37:02,001][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=[emmental_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-28 02:37:02,092][INFO] emmental.logging.logging_manager:33 - Evaluating every 100 batch.\n",
      "[2019-05-28 02:37:02,093][INFO] emmental.logging.logging_manager:51 - No checkpointing.\n",
      "[2019-05-28 02:37:02,138][INFO] root:123 - Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "[2019-05-28 02:37:02,185][INFO] root:123 - Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
      "[2019-05-28 02:37:02,314][INFO] emmental.learner:152 - Warmup 100 batchs.\n",
      "[2019-05-28 02:37:02,318][INFO] emmental.learner:298 - Start learning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c57a44eb3814901964ca421e9b54f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed349cabdbad4721b1357289c9b08a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03cd75ac91442cbba56f4583c111b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85128bb3c5ed419fbb157dfdd3443fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b0f52b25a44f9d900de7b02f1f3f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69179f65294b4438840b634787131afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd9beafa89f470e88f7f8d3e62e251b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b6a1056bee4244aa970e8ff3d163ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a65db9ef67a41fdafa5b89bbb9f45b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a289f6bce1e4781adc0d4059a367c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9:', style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emmental_learner.learn(mtl_model, dataloaders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COPA/SuperGLUE/val/accuracy': 0.6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COPA/SuperGLUE/train/accuracy': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COPA/SuperGLUE/val/accuracy': 0.6}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = mtl_model.predict(dataloaders[\"val\"], return_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'COPA': array([2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2,\n",
       "                    1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1,\n",
       "                    2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1,\n",
       "                    1, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "                    1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2])})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'COPA': array([1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2,\n",
       "                    2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2,\n",
       "                    1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1,\n",
       "                    1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2])})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'COPA': array([[9.99761522e-01, 2.38526700e-04],\n",
       "                    [1.69803783e-01, 8.30196202e-01],\n",
       "                    [5.43002822e-02, 9.45699692e-01],\n",
       "                    [9.39647257e-01, 6.03526980e-02],\n",
       "                    [5.59555786e-03, 9.94404435e-01],\n",
       "                    [3.17611635e-01, 6.82388365e-01],\n",
       "                    [9.99995947e-01, 4.09298946e-06],\n",
       "                    [9.25400972e-01, 7.45989755e-02],\n",
       "                    [5.81856608e-01, 4.18143421e-01],\n",
       "                    [9.97979581e-01, 2.02048244e-03],\n",
       "                    [1.68916536e-04, 9.99831080e-01],\n",
       "                    [3.77696753e-02, 9.62230265e-01],\n",
       "                    [1.21609941e-04, 9.99878407e-01],\n",
       "                    [2.07558796e-02, 9.79244173e-01],\n",
       "                    [1.82919607e-01, 8.17080379e-01],\n",
       "                    [2.54585780e-03, 9.97454107e-01],\n",
       "                    [9.98093426e-01, 1.90656923e-03],\n",
       "                    [5.52746579e-02, 9.44725275e-01],\n",
       "                    [3.31966102e-01, 6.68033898e-01],\n",
       "                    [4.49173676e-05, 9.99955058e-01],\n",
       "                    [6.21161580e-01, 3.78838390e-01],\n",
       "                    [9.99122322e-01, 8.77703656e-04],\n",
       "                    [9.99341428e-01, 6.58555829e-04],\n",
       "                    [6.86095178e-01, 3.13904822e-01],\n",
       "                    [8.95486832e-01, 1.04513191e-01],\n",
       "                    [9.99928236e-01, 7.18149968e-05],\n",
       "                    [9.68301296e-01, 3.16987522e-02],\n",
       "                    [7.89156556e-02, 9.21084344e-01],\n",
       "                    [7.33879453e-04, 9.99266088e-01],\n",
       "                    [6.71622276e-01, 3.28377724e-01],\n",
       "                    [3.70986611e-02, 9.62901354e-01],\n",
       "                    [7.44662287e-08, 9.99999881e-01],\n",
       "                    [3.39386240e-02, 9.66061294e-01],\n",
       "                    [8.28484911e-03, 9.91715133e-01],\n",
       "                    [7.52773285e-02, 9.24722672e-01],\n",
       "                    [1.84482671e-02, 9.81551707e-01],\n",
       "                    [1.44894153e-03, 9.98551071e-01],\n",
       "                    [1.25771128e-02, 9.87422943e-01],\n",
       "                    [9.99932766e-01, 6.72587994e-05],\n",
       "                    [9.94757950e-01, 5.24198823e-03],\n",
       "                    [4.46977794e-01, 5.53022206e-01],\n",
       "                    [9.63317811e-01, 3.66822369e-02],\n",
       "                    [9.99727547e-01, 2.72477104e-04],\n",
       "                    [8.01316798e-02, 9.19868290e-01],\n",
       "                    [2.06766516e-01, 7.93233454e-01],\n",
       "                    [9.93180513e-01, 6.81949593e-03],\n",
       "                    [5.83171070e-01, 4.16828930e-01],\n",
       "                    [9.99680519e-01, 3.19556217e-04],\n",
       "                    [9.98286903e-01, 1.71313644e-03],\n",
       "                    [9.69625771e-01, 3.03742122e-02],\n",
       "                    [9.81710136e-01, 1.82898529e-02],\n",
       "                    [1.10829053e-02, 9.88917112e-01],\n",
       "                    [9.99531507e-01, 4.68470244e-04],\n",
       "                    [9.91377115e-01, 8.62292293e-03],\n",
       "                    [9.38675821e-01, 6.13241866e-02],\n",
       "                    [9.69439685e-01, 3.05603649e-02],\n",
       "                    [9.99936700e-01, 6.33546224e-05],\n",
       "                    [9.98056293e-01, 1.94371212e-03],\n",
       "                    [6.59140712e-03, 9.93408561e-01],\n",
       "                    [9.99966621e-01, 3.34360848e-05],\n",
       "                    [9.55943577e-03, 9.90440607e-01],\n",
       "                    [1.98818035e-02, 9.80118155e-01],\n",
       "                    [9.30826366e-01, 6.91736266e-02],\n",
       "                    [3.83621454e-01, 6.16378605e-01],\n",
       "                    [9.34457600e-01, 6.55423775e-02],\n",
       "                    [9.06761488e-06, 9.99990940e-01],\n",
       "                    [9.38756585e-01, 6.12433776e-02],\n",
       "                    [9.03981738e-03, 9.90960240e-01],\n",
       "                    [9.99300241e-01, 6.99742464e-04],\n",
       "                    [6.80476129e-01, 3.19523871e-01],\n",
       "                    [5.48634648e-01, 4.51365352e-01],\n",
       "                    [3.08565999e-04, 9.99691486e-01],\n",
       "                    [9.16800201e-01, 8.31998661e-02],\n",
       "                    [8.62200022e-01, 1.37799978e-01],\n",
       "                    [1.13870129e-02, 9.88613009e-01],\n",
       "                    [5.00089861e-03, 9.94999170e-01],\n",
       "                    [9.44015443e-01, 5.59845455e-02],\n",
       "                    [9.98198092e-01, 1.80192664e-03],\n",
       "                    [9.43360865e-01, 5.66391759e-02],\n",
       "                    [2.42445618e-02, 9.75755513e-01],\n",
       "                    [9.99716938e-01, 2.83085275e-04],\n",
       "                    [9.94646847e-01, 5.35314064e-03],\n",
       "                    [8.03552866e-01, 1.96447164e-01],\n",
       "                    [9.71299529e-01, 2.87004299e-02],\n",
       "                    [1.08377812e-04, 9.99891639e-01],\n",
       "                    [7.81827748e-01, 2.18172282e-01],\n",
       "                    [9.25000429e-01, 7.49995261e-02],\n",
       "                    [9.99928355e-01, 7.16222567e-05],\n",
       "                    [8.80144596e-01, 1.19855389e-01],\n",
       "                    [9.92754281e-01, 7.24574504e-03],\n",
       "                    [4.92644757e-01, 5.07355273e-01],\n",
       "                    [9.99985456e-01, 1.45347294e-05],\n",
       "                    [7.53882229e-01, 2.46117786e-01],\n",
       "                    [9.99716699e-01, 2.83322326e-04],\n",
       "                    [9.99882221e-01, 1.17747506e-04],\n",
       "                    [6.66514158e-01, 3.33485842e-01],\n",
       "                    [2.58621597e-03, 9.97413814e-01],\n",
       "                    [9.15309370e-01, 8.46906453e-02],\n",
       "                    [9.92581367e-01, 7.41855940e-03],\n",
       "                    [1.42927642e-03, 9.98570681e-01]], dtype=float32)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
