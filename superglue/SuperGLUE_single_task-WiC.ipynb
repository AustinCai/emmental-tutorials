{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from parse_WiC import get_WiC_dataloaders\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:11:56,143][INFO] emmental.meta:95 - Setting logging directory to: logs/2019_05_30/16_11_56\n",
      "[2019-05-30 16:11:56,154][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch0/bradenjh/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-05-30 16:11:56,154][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 4,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\n",
    "                \"warmup_percentage\": 0.1,\n",
    "                \"lr_scheduler\": None,\n",
    "            },\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 100,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": {\"WiC/SuperGLUE/val/accuracy\":\"max\"},\n",
    "                \"checkpoint_freq\": 1,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta_config': {'seed': 0, 'verbose': True, 'log_path': None},\n",
       " 'model_config': {'model_path': None, 'device': 0, 'dataparallel': False},\n",
       " 'learner_config': {'fp16': False,\n",
       "  'n_epochs': 4,\n",
       "  'train_split': 'train',\n",
       "  'valid_split': 'val',\n",
       "  'test_split': 'test',\n",
       "  'ignore_index': -100,\n",
       "  'optimizer_config': {'optimizer': 'adam',\n",
       "   'lr': 1e-05,\n",
       "   'l2': 0.0,\n",
       "   'grad_clip': 1.0,\n",
       "   'sgd_config': {'momentum': 0.9},\n",
       "   'adam_config': {'betas': (0.9, 0.999)}},\n",
       "  'lr_scheduler_config': {'lr_scheduler': None,\n",
       "   'warmup_steps': None,\n",
       "   'warmup_unit': 'batch',\n",
       "   'warmup_percentage': 0.1,\n",
       "   'min_lr': 0.0,\n",
       "   'linear_config': {'min_lr': 0.0},\n",
       "   'exponential_config': {'gamma': 0.9},\n",
       "   'plateau_config': {'factor': 0.5, 'patience': 10, 'threshold': 0.0001}},\n",
       "  'task_scheduler': 'round_robin',\n",
       "  'global_evaluation_metric_dict': None,\n",
       "  'min_lr': 0},\n",
       " 'logging_config': {'counter_unit': 'batch',\n",
       "  'evaluation_freq': 100,\n",
       "  'writer_config': {'writer': 'tensorboard', 'verbose': True},\n",
       "  'checkpointing': True,\n",
       "  'checkpointer_config': {'checkpoint_path': None,\n",
       "   'checkpoint_freq': 1,\n",
       "   'checkpoint_metric': {'WiC/SuperGLUE/val/accuracy': 'max'},\n",
       "   'checkpoint_task_metrics': None,\n",
       "   'checkpoint_runway': 0,\n",
       "   'checkpoint_clear': True}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TASK_NAME = \"WiC\"\n",
    "DATA_DIR = \"/dfs/scratch0/bradenjh/superglue\" #os.environ[\"SUPERGLUEDATA\"]\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:11:56,322][INFO] tokenizer:8 - Loading Tokenizer bert-large-cased\n",
      "[2019-05-30 16:11:56,588][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /afs/cs.stanford.edu/u/bradenjh/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/bradenjh/superglue/WiC/train.jsonl\n",
      "{'label': False, 'word': 'carry', 'pos': 'V', 'sentence1': 'You must carry your camping gear .', 'sentence2': 'Sound carries well over water .', 'sentence1_idx': '2', 'sentence2_idx': '1', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:11:58,519][INFO] parse_WiC:154 - Loaded train for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 68\n",
      "/dfs/scratch0/bradenjh/superglue/WiC/val.jsonl\n",
      "{'label': False, 'word': 'board', 'pos': 'N', 'sentence1': 'Room and board .', 'sentence2': 'He nailed boards across the windows .', 'sentence1_idx': '2', 'sentence2_idx': '2', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:11:58,826][INFO] parse_WiC:154 - Loaded val for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 57\n",
      "/dfs/scratch0/bradenjh/superglue/WiC/test.jsonl\n",
      "{'word': 'defeat', 'pos': 'N', 'sentence1': 'It was a narrow defeat .', 'sentence2': \"The army 's only defeat .\", 'sentence1_idx': '4', 'sentence2_idx': '4', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:11:59,354][INFO] parse_WiC:154 - Loaded test for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 60\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_WiC_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\", \"test\"],\n",
    "    max_sequence_length=128,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(task_name, immediate_ouput_dict, Y, active):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(task_name, immediate_ouput_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(golds, probs, preds):\n",
    "    return {\"macro_f1\": f1_score(golds, preds, average=\"macro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, feature, idx1, idx2):\n",
    "        last_layer = feature[-1]\n",
    "        emb = last_layer[:,0,:]\n",
    "        idx1 = idx1.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        idx2 = idx2.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        word1_emb = last_layer.gather(dim=1, index=idx1).squeeze(dim=1)\n",
    "        word2_emb = last_layer.gather(dim=1, index=idx2).squeeze(dim=1)\n",
    "        input = torch.cat([emb, word1_emb, word2_emb], dim=-1)\n",
    "        return self.linear.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:11:59,844][INFO] pytorch_pretrained_bert.modeling:580 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "[2019-05-30 16:11:59,845][INFO] pytorch_pretrained_bert.modeling:588 - extracting archive file ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpm0qfx241\n",
      "[2019-05-30 16:12:12,072][INFO] pytorch_pretrained_bert.modeling:598 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[2019-05-30 16:12:19,619][INFO] emmental.task:34 - Created task: WiC\n"
     ]
    }
   ],
   "source": [
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")\n",
    "\n",
    "emmental_task = EmmentalTask(\n",
    "    name=TASK_NAME,\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "            f\"{TASK_NAME}_pred_head\": LinearModule(3 * BERT_OUTPUT_DIM, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": \"input\",\n",
    "            \"module\": \"bert_module\",\n",
    "            \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "        },\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [(\"input\", 0), (\"_input_\", \"sent1_idxs\"), (\"_input_\", \"sent2_idxs\")],\n",
    "        },\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, TASK_NAME),\n",
    "    output_func=partial(output, TASK_NAME),\n",
    "    scorer=Scorer(\n",
    "        metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:12:19,695][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-05-30 16:12:23,153][INFO] emmental.model:44 - Created emmental model SuperGLUE_single_task that contains task {'WiC'}.\n",
      "[2019-05-30 16:12:23,154][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=[emmental_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# emmental_learner.learn(mtl_model, dataloaders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WiC/SuperGLUE/val/accuracy': 0.5047021943573667}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WiC/SuperGLUE/train/accuracy': 0.502210759027266}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mtl_model.score(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PKL_PATH = \"/dfs/scratch0/bradenjh/emmental-tutorials/superglue/models/WiC_BERT2\"\n",
    "PKL_PATH = \"/dfs/scratch0/bradenjh/emmental-tutorials/superglue/logs/2019_05_29/13_59_55/best_model_WiC_SuperGLUE_val_accuracy.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.save(PKL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:14:10,313][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-05-30 16:14:10,318][INFO] emmental.model:44 - Created emmental model SuperGLUE_single_task that contains task {'WiC'}.\n",
      "[2019-05-30 16:14:10,319][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'modules.bert_module.BertModule' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "[2019-05-30 16:14:23,070][INFO] emmental.model:412 - [SuperGLUE_single_task] Model loaded from /dfs/scratch0/bradenjh/emmental-tutorials/superglue/logs/2019_05_29/13_59_55/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 16:14:23,072][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WiC/SuperGLUE/val/accuracy': 0.731974921630094}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=[emmental_task])\n",
    "new_model.load(PKL_PATH)\n",
    "new_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from task_config import (\n",
    "    SuperGLUE_LABEL_MAPPING, \n",
    "    SuperGLUE_TASK_METRIC_MAPPING, \n",
    "    SuperGLUE_TASK_SPLIT_MAPPING\n",
    ")\n",
    "\n",
    "SPLIT = \"val\"\n",
    "\n",
    "def make_analysis_df(model):\n",
    "    # Get predictions\n",
    "    gold_dict, prob_dict, pred_dict = model.predict(dataloaders[SPLIT], return_preds=True)\n",
    "    probs = prob_dict[\"WiC\"][:,0]\n",
    "    preds = pred_dict[\"WiC\"]\n",
    "\n",
    "    # Load raw data\n",
    "    jsonl_path = os.path.join(\n",
    "        DATA_DIR, TASK_NAME, SuperGLUE_TASK_SPLIT_MAPPING[TASK_NAME][SPLIT]\n",
    "    )\n",
    "\n",
    "    # Add new columns\n",
    "    rows = [json.loads(row) for row in open(jsonl_path, encoding=\"utf-8\")]\n",
    "    for i, row in enumerate(rows):\n",
    "        row[\"prob\"] = probs[i]\n",
    "        row[\"pred\"] = True if preds[i] == 1 else False\n",
    "        row[\"correct\"] = \"Y\" if row[\"pred\"] == row[\"label\"] else \"N\"\n",
    "\n",
    "    # Make tsv\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df[['idx', 'label', 'pred', 'prob', 'correct', 'word', 'pos', 'sentence1', 'sentence2']]\n",
    "    return df\n",
    "\n",
    "df = make_analysis_df(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote error analysis to /dfs/scratch0/bradenjh/emmental-tutorials/superglue/analysis/WiC_val_analysis_v0.csv\n"
     ]
    }
   ],
   "source": [
    "TUTORIALS_ROOT = \"/dfs/scratch0/bradenjh/emmental-tutorials/\"\n",
    "\n",
    "out_path = os.path.join(TUTORIALS_ROOT, \"superglue\", \"analysis\", f\"WiC_{SPLIT}_analysis_v0.csv\")\n",
    "df.to_csv(out_path)\n",
    "print(f\"Wrote error analysis to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "      <th>correct</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>Y</td>\n",
       "      <td>board</td>\n",
       "      <td>N</td>\n",
       "      <td>Room and board .</td>\n",
       "      <td>He nailed boards across the windows .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  label   pred      prob correct   word pos         sentence1  \\\n",
       "0    0  False  False  0.001316       Y  board   N  Room and board .   \n",
       "\n",
       "                               sentence2  \n",
       "0  He nailed boards across the windows .  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['on the bridge', 'the bridge of'], ['break the bridge', 'the bridge of']]\n",
      "bridge: Her glasses left marks on the bridge of her nose ......Rugby players often break the bridge of their noses .\n",
      "\n",
      "[['at the finish', 'the finish .'], ['at the finish', 'the finish .']]\n",
      "finish: My horse was several lengths behind at the finish ......The winner is the team with the most points at the finish .\n",
      "\n",
      "[['Sculpture in contradistinction', 'in contradistinction to'], ['soda in contradistinction', 'in contradistinction to']]\n",
      "contradistinction: Sculpture in contradistinction to painting ......We used hamburgers and soda in contradistinction to healthy food .\n",
      "\n",
      "[['felt a stream', 'a stream of'], ['ejected a stream', 'a stream of']]\n",
      "stream: He felt a stream of air ......The hose ejected a stream of water .\n",
      "\n",
      "[['is an obstacle', 'an obstacle to'], ['is an obstacle', 'an obstacle to']]\n",
      "obstacle: Lack of imagination is an obstacle to one 's advancement ......The poverty of a district is an obstacle to good education .\n",
      "\n",
      "[['catch a glimpse', 'a glimpse of'], ['only a glimpse', 'a glimpse of']]\n",
      "glimpse: From the window he could catch a glimpse of the lake ......He caught only a glimpse of the professor 's meaning .\n",
      "\n",
      "[['influence the arousal', 'the arousal of'], ['is the arousal', 'the arousal of']]\n",
      "arousal: To influence the arousal of brain and behavior ......The purpose of art is the arousal of emotions .\n",
      "\n",
      "[['is a blend', 'a blend of'], ['as a blend', 'a blend of']]\n",
      "blend: ` smog ' is a blend of ` smoke ' and ` fog ' ......Their music has been described as a blend of jazz and heavy metal .\n",
      "\n",
      "[['stay within earshot', 'within earshot .'], ['stay within earshot', 'within earshot .']]\n",
      "earshot: I 'll row out on the lake but stay within earshot ......The children were told to stay within earshot .\n",
      "\n",
      "[['is a member', 'a member of'], ['was a member', 'a member of']]\n",
      "member: Canada is a member of the United Nations ......The library was a member of the interlibrary loan association .\n",
      "\n",
      "[['missed his connection', 'his connection at'], ['missed his connection', 'his connection in']]\n",
      "connection: The bus was late so he missed his connection at Penn Station and had to wait six hours for the next train ......The plane was late and he missed his connection in Atlanta .\n",
      "\n",
      "[['In the middle', 'the middle of'], ['during the middle', 'the middle of']]\n",
      "middle: In the middle of the marathon , David collapsed from fatigue ......Rain during the middle of April .\n",
      "\n",
      "[['down the gauntlet', 'the gauntlet .'], ['up the gauntlet', 'the gauntlet .']]\n",
      "gauntlet: Threw down the gauntlet ......Took up the gauntlet .\n",
      "\n",
      "[['in the twilight', 'the twilight .'], ['loved the twilight', 'the twilight .']]\n",
      "twilight: I could just make out her face in the twilight ......He loved the twilight .\n",
      "\n",
      "[['for the piano', 'the piano .'], ['on the piano', 'the piano .']]\n",
      "piano: Most of the works by Frédéric Chopin are for the piano ......He can play \" Happy Birthday \" on the piano .\n",
      "\n",
      "[['conceal his hostility', 'his hostility .'], ['contain his hostility', 'his hostility .']]\n",
      "hostility: He could not conceal his hostility ......He could no longer contain his hostility .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "def get_ngrams(tokens, window=1):\n",
    "    num_ngrams = len(tokens) - window + 1\n",
    "    for i in range(num_ngrams):\n",
    "        yield tokens[i:i+window]\n",
    "        \n",
    "for index, row in df.iterrows():\n",
    "    word = row[\"word\"]\n",
    "    labels.append(1 if row[\"label\"] == True else 2)\n",
    "    trigrams = []\n",
    "    for sent in [\"sentence1\", \"sentence2\"]:\n",
    "        tokens = row[sent].split()\n",
    "#         if sum([word in tok for tok in tokens]) > 1:\n",
    "#             print(row[sent])\n",
    "        for i, tok in enumerate(tokens):\n",
    "            if word in tok:\n",
    "                idx = i\n",
    "                break\n",
    "        trigrams.append([' '.join(ngram) \n",
    "                         for ngram in get_ngrams(tokens[idx-2:idx+2], window=3) \n",
    "                         if len(ngram) == 3])\n",
    "    if (set(trigrams[0]).intersection(set(trigrams[1]))):\n",
    "        preds.append(1)\n",
    "        print(trigrams)\n",
    "        print(f\"{word}: {row['sentence1']}.....{row['sentence2']}\")\n",
    "        print()        \n",
    "    else:\n",
    "        preds.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.025078369905956112\n"
     ]
    }
   ],
   "source": [
    "from metal.metrics import *\n",
    "\n",
    "print(accuracy_score(labels, preds, ignore_in_pred=[0]))\n",
    "print(coverage_score(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
