{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from parse_WiC_slice import get_WiC_dataloaders\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:23:57 - INFO - emmental.meta -   Setting logging directory to: logs/2019_05_22/15_23_57\n",
      "05/22/2019 15:23:57 - INFO - emmental.meta -   Loading Emmental default config from /dfs/scratch1/senwu/mmtl/emmental/src/emmental/emmental-default-config.yaml.\n",
      "05/22/2019 15:23:57 - INFO - emmental.meta -   Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 10,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\"warmup_percentage\": 0.1, \"lr_scheduler\": None},\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 100,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\"checkpoint_metric\": {\"WiC/SuperGLUE/val/accuracy\":\"max\"}},\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta_config': {'seed': 0, 'verbose': True, 'log_path': None},\n",
       " 'model_config': {'model_path': None, 'device': 0, 'dataparallel': False},\n",
       " 'learner_config': {'fp16': False,\n",
       "  'n_epochs': 10,\n",
       "  'train_split': 'train',\n",
       "  'valid_split': 'val',\n",
       "  'test_split': 'test',\n",
       "  'ignore_index': -100,\n",
       "  'optimizer_config': {'optimizer': 'adam',\n",
       "   'lr': 1e-05,\n",
       "   'l2': 0.0,\n",
       "   'grad_clip': 1.0,\n",
       "   'sgd_config': {'momentum': 0.9},\n",
       "   'adam_config': {'betas': (0.9, 0.999)}},\n",
       "  'lr_scheduler_config': {'lr_scheduler': None,\n",
       "   'warmup_steps': None,\n",
       "   'warmup_unit': 'batch',\n",
       "   'warmup_percentage': 0.1,\n",
       "   'min_lr': 0.0,\n",
       "   'linear_config': {'min_lr': 0.0},\n",
       "   'exponential_config': {'gamma': 0.9},\n",
       "   'plateau_config': {'factor': 0.5, 'patience': 10, 'threshold': 0.0001}},\n",
       "  'task_scheduler': 'round_robin',\n",
       "  'global_evaluation_metric_dict': None,\n",
       "  'min_lr': 0},\n",
       " 'logging_config': {'counter_unit': 'batch',\n",
       "  'evaluation_freq': 100,\n",
       "  'writer_config': {'writer': 'tensorboard', 'verbose': True},\n",
       "  'checkpointing': True,\n",
       "  'checkpointer_config': {'checkpoint_path': None,\n",
       "   'checkpoint_freq': 1,\n",
       "   'checkpoint_metric': {'WiC/SuperGLUE/val/accuracy': 'max'},\n",
       "   'checkpoint_task_metrics': None,\n",
       "   'checkpoint_runway': 0,\n",
       "   'checkpoint_clear': True}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"WiC\"\n",
    "DATA_DIR = \"data\"\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_OUTPUT_DIM, TASK_CARDINALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_verb(dataset):\n",
    "    slice_name = \"slice_verb\"\n",
    "    ind, pred = [], []\n",
    "    cnt = 0\n",
    "    for idx, pos in enumerate(dataset.X_dict[\"poses\"]):\n",
    "        if pos == \"V\":\n",
    "            ind.append(1)\n",
    "            pred.append(dataset.Y_dict[\"labels\"][idx])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ind.append(2)\n",
    "            pred.append(Meta.config[\"learner_config\"][\"ignore_index\"])\n",
    "    ind = torch.from_numpy(np.array(ind)).view(-1)\n",
    "    pred = torch.from_numpy(np.array(pred)).view(-1)\n",
    "    logger.info(f\"Total {cnt} / {len(dataset)} in the slice {slice_name}\")\n",
    "    print(ind.size(), pred.size())\n",
    "    return ind, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_noun(dataset):\n",
    "    slice_name = \"slice_noun\"\n",
    "    ind, pred = [], []\n",
    "    cnt = 0\n",
    "    for idx, pos in enumerate(dataset.X_dict[\"poses\"]):\n",
    "        if pos == \"N\":\n",
    "            ind.append(1)\n",
    "            pred.append(dataset.Y_dict[\"labels\"][idx])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ind.append(2)\n",
    "            pred.append(Meta.config[\"learner_config\"][\"ignore_index\"])\n",
    "    ind = torch.from_numpy(np.array(ind)).view(-1)\n",
    "    pred = torch.from_numpy(np.array(pred)).view(-1)\n",
    "    logger.info(f\"Total {cnt} / {len(dataset)} in the slice {slice_name}\")\n",
    "    print(ind.size(), pred.size())\n",
    "    return ind, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_first_pos(dataset):\n",
    "    slice_name = \"slice_first_pos\"\n",
    "    ind, pred = [], []\n",
    "    cnt = 0\n",
    "    for idx, pos in enumerate(dataset.X_dict[\"poses\"]):\n",
    "        if dataset.X_dict[\"sent1_ori_idxs\"][idx] == 1 and dataset.X_dict[\"sent2_ori_idxs\"][idx] == 1:\n",
    "            ind.append(1)\n",
    "            pred.append(dataset.Y_dict[\"labels\"][idx])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ind.append(2)\n",
    "            pred.append(Meta.config[\"learner_config\"][\"ignore_index\"])\n",
    "    ind = torch.from_numpy(np.array(ind)).view(-1)\n",
    "    pred = torch.from_numpy(np.array(pred)).view(-1)\n",
    "    logger.info(f\"Total {cnt} / {len(dataset)} in the slice {slice_name}\")\n",
    "    print(ind.size(), pred.size())\n",
    "    return ind, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_base(dataset):\n",
    "    return torch.from_numpy(np.array([1] * len(dataset))), dataset.Y_dict[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['slice_base', 'slice_verb', 'slice_noun', 'slice_first_pos'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_func_dict = {\n",
    "    \"slice_base\": slice_base,\n",
    "    \"slice_verb\": slice_verb,\n",
    "    \"slice_noun\": slice_noun,\n",
    "    \"slice_first_pos\": slice_first_pos,\n",
    "}\n",
    "slice_func_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:23:59 - INFO - tokenizer -   Loading Tokenizer bert-large-cased\n",
      "05/22/2019 15:23:59 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "05/22/2019 15:24:03 - INFO - __main__ -   Total 2634 / 5428 in the slice slice_verb\n",
      "05/22/2019 15:24:03 - INFO - __main__ -   Total 2794 / 5428 in the slice slice_noun\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 68\n",
      "torch.Size([5428]) torch.Size([5428])\n",
      "torch.Size([5428]) torch.Size([5428])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:03 - INFO - __main__ -   Total 869 / 5428 in the slice slice_first_pos\n",
      "05/22/2019 15:24:03 - INFO - parse_WiC_slice -   Loaded train for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5428]) torch.Size([5428])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:03 - INFO - __main__ -   Total 243 / 638 in the slice slice_verb\n",
      "05/22/2019 15:24:03 - INFO - __main__ -   Total 395 / 638 in the slice slice_noun\n",
      "05/22/2019 15:24:03 - INFO - __main__ -   Total 129 / 638 in the slice slice_first_pos\n",
      "05/22/2019 15:24:03 - INFO - parse_WiC_slice -   Loaded val for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 57\n",
      "torch.Size([638]) torch.Size([638])\n",
      "torch.Size([638]) torch.Size([638])\n",
      "torch.Size([638]) torch.Size([638])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:04 - INFO - __main__ -   Total 569 / 1400 in the slice slice_verb\n",
      "05/22/2019 15:24:04 - INFO - __main__ -   Total 831 / 1400 in the slice slice_noun\n",
      "05/22/2019 15:24:04 - INFO - __main__ -   Total 240 / 1400 in the slice slice_first_pos\n",
      "05/22/2019 15:24:04 - INFO - parse_WiC_slice -   Loaded test for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 60\n",
      "torch.Size([1400]) torch.Size([1400])\n",
      "torch.Size([1400]) torch.Size([1400])\n",
      "torch.Size([1400]) torch.Size([1400])\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_WiC_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\", \"test\"],\n",
    "    max_sequence_length=128,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    slice_func_dict=slice_func_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([2, 2, 2,  ..., 1, 1, 1]),\n",
       " 'WiC_slice_ind_slice_base': tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       " 'WiC_slice_pred_slice_base': tensor([2, 2, 2,  ..., 1, 1, 1]),\n",
       " 'WiC_slice_ind_slice_verb': tensor([1, 1, 1,  ..., 1, 1, 2]),\n",
       " 'WiC_slice_pred_slice_verb': tensor([   2,    2,    2,  ...,    1,    1, -100]),\n",
       " 'WiC_slice_ind_slice_noun': tensor([2, 2, 2,  ..., 2, 2, 1]),\n",
       " 'WiC_slice_pred_slice_noun': tensor([-100, -100, -100,  ..., -100, -100,    1]),\n",
       " 'WiC_slice_ind_slice_first_pos': tensor([2, 2, 2,  ..., 2, 2, 1]),\n",
       " 'WiC_slice_pred_slice_first_pos': tensor([-100, -100, -100,  ..., -100, -100,    1])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders[\"train\"].dataset.Y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WiC_slice_ind_slice_base': 'WiC_slice_ind_slice_base',\n",
       " 'WiC_slice_pred_slice_base': 'WiC_slice_pred_slice_base',\n",
       " 'WiC_slice_ind_slice_verb': 'WiC_slice_ind_slice_verb',\n",
       " 'WiC_slice_pred_slice_verb': 'WiC_slice_pred_slice_verb',\n",
       " 'WiC_slice_ind_slice_noun': 'WiC_slice_ind_slice_noun',\n",
       " 'WiC_slice_pred_slice_noun': 'WiC_slice_pred_slice_noun',\n",
       " 'WiC_slice_ind_slice_first_pos': 'WiC_slice_ind_slice_first_pos',\n",
       " 'WiC_slice_pred_slice_first_pos': 'WiC_slice_pred_slice_first_pos',\n",
       " 'WiC': 'labels'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders[\"train\"].task_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels torch.Size([5428])\n",
      "WiC_slice_ind_slice_base torch.Size([5428])\n",
      "WiC_slice_pred_slice_base torch.Size([5428])\n",
      "WiC_slice_ind_slice_verb torch.Size([5428])\n",
      "WiC_slice_pred_slice_verb torch.Size([5428])\n",
      "WiC_slice_ind_slice_noun torch.Size([5428])\n",
      "WiC_slice_pred_slice_noun torch.Size([5428])\n",
      "WiC_slice_ind_slice_first_pos torch.Size([5428])\n",
      "WiC_slice_pred_slice_first_pos torch.Size([5428])\n"
     ]
    }
   ],
   "source": [
    "for key, value in dataloaders[\"train\"].dataset.Y_dict.items():\n",
    "    print(key, value.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(module_name, immediate_ouput_dict, Y, active):\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(module_name, immediate_ouput_dict):\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureConcateModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, feature, idx1, idx2):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        last_layer = feature[-1]\n",
    "        emb = last_layer[:,0,:]\n",
    "        idx1 = idx1.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        idx2 = idx2.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        word1_emb = last_layer.gather(dim=1, index=idx1).squeeze(dim=1)\n",
    "        word2_emb = last_layer.gather(dim=1, index=idx2).squeeze(dim=1)\n",
    "        input = torch.cat([emb, word1_emb, word2_emb], dim=-1)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        return self.linear.forward(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = BERT_OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_classification_module = nn.Linear(H, TASK_CARDINALITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:05 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "05/22/2019 15:24:05 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpumrkv2e0\n",
      "05/22/2019 15:24:22 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_module = BertModule(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_ind_slice_base\n",
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_ind_slice_verb\n",
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_ind_slice_noun\n",
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_ind_slice_first_pos\n"
     ]
    }
   ],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"ind\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": SliceModule(\n",
    "                    3 * BERT_OUTPUT_DIM, 2\n",
    "                ),\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"feature\",\n",
    "                \"module\": f\"feature\",\n",
    "                \"inputs\": [\n",
    "                    (\"input\", 0),\n",
    "                    (\"_input_\", \"sent1_idxs\"),\n",
    "                    (\"_input_\", \"sent2_idxs\"),\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(metrics=[\"accuracy\"]),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_pred_slice_base\n",
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_pred_slice_verb\n",
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_pred_slice_noun\n",
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC_slice_pred_slice_first_pos\n"
     ]
    }
   ],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"pred\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_feat_{slice_name}\": nn.Linear(3 * BERT_OUTPUT_DIM, H),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": shared_classification_module,\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"feature\",\n",
    "                \"module\": f\"feature\",\n",
    "                \"inputs\": [\n",
    "                    (\"input\", 0),\n",
    "                    (\"_input_\", \"sent1_idxs\"),\n",
    "                    (\"_input_\", \"sent2_idxs\"),\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(f\"{TASK_NAME}_slice_feat_{slice_name}\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, immediate_ouput_dict):\n",
    "        slice_ind_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_ind_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "        slice_pred_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_pred_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        Q = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_ind_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_ind_name in slice_ind_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        P = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_pred_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_pred_name in slice_pred_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        slice_feat_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_feat_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        slice_reps = torch.cat(\n",
    "            [\n",
    "                immediate_ouput_dict[slice_feat_name][0].unsqueeze(1)\n",
    "                for slice_feat_name in slice_feat_names\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        A = F.softmax(Q * P, dim=1).unsqueeze(-1).expand([-1, -1, slice_reps.size(-1)])\n",
    "\n",
    "        reweighted_rep = torch.sum(A * slice_reps, 1)\n",
    "\n",
    "        return self.linear.forward(reweighted_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:54 - INFO - emmental.task -   Created task: WiC\n"
     ]
    }
   ],
   "source": [
    "master_task = EmmentalTask(\n",
    "    name=f\"{TASK_NAME}\",\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": bert_module,\n",
    "            f\"{TASK_NAME}_pred_head\": MasterModule(H, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [],\n",
    "        }\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, f\"{TASK_NAME}_pred_head\"),\n",
    "    output_func=partial(output, f\"{TASK_NAME}_pred_head\"),\n",
    "    scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    ")\n",
    "tasks.append(master_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:24:54 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:24:59 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n",
      "05/22/2019 15:25:00 - INFO - emmental.model -   Created emmental model SuperGLUE_single_task that contains task {'WiC_slice_pred_slice_base', 'WiC_slice_pred_slice_verb', 'WiC_slice_ind_slice_noun', 'WiC_slice_ind_slice_first_pos', 'WiC_slice_ind_slice_verb', 'WiC_slice_ind_slice_base', 'WiC', 'WiC_slice_pred_slice_noun', 'WiC_slice_pred_slice_first_pos'}.\n",
      "05/22/2019 15:25:00 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for X, Y in dataloaders[\"train\"]:\n",
    "#     import pdb; pdb.set_trace()\n",
    "# # #     print(X, Y)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:25:00 - INFO - emmental.logging.logging_manager -   Evaluating every 100 batch.\n",
      "05/22/2019 15:25:00 - INFO - emmental.logging.logging_manager -   Checkpointing every 100 batch.\n",
      "05/22/2019 15:25:00 - INFO - emmental.logging.checkpointer -   Save checkpoints at logs/2019_05_22/15_23_57 every 100 batch\n",
      "05/22/2019 15:25:00 - INFO - emmental.logging.checkpointer -   No checkpoints saved before 0 batch.\n",
      "05/22/2019 15:25:00 - INFO - root -   Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "05/22/2019 15:25:00 - INFO - root -   Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
      "05/22/2019 15:25:00 - INFO - emmental.learner -   Warmup 1357 batchs.\n",
      "05/22/2019 15:25:00 - INFO - emmental.learner -   Start learning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c03092e6fec4f1086c58916fd44f50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "05/22/2019 15:26:08 - INFO - emmental.logging.checkpointer -   checkpoint_runway condition has been met. Start checkpoining.\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SliceModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type FeatureConcateModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MasterModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "05/22/2019 15:26:20 - INFO - emmental.logging.checkpointer -   Save checkpoint of 100 batch at logs/2019_05_22/15_23_57/checkpoint_100.pth.\n",
      "05/22/2019 15:26:33 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:27:53 - INFO - emmental.logging.checkpointer -   Save checkpoint of 200 batch at logs/2019_05_22/15_23_57/checkpoint_200.pth.\n",
      "05/22/2019 15:28:05 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:29:24 - INFO - emmental.logging.checkpointer -   Save checkpoint of 300 batch at logs/2019_05_22/15_23_57/checkpoint_300.pth.\n",
      "05/22/2019 15:29:36 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:30:56 - INFO - emmental.logging.checkpointer -   Save checkpoint of 400 batch at logs/2019_05_22/15_23_57/checkpoint_400.pth.\n",
      "05/22/2019 15:32:15 - INFO - emmental.logging.checkpointer -   Save checkpoint of 500 batch at logs/2019_05_22/15_23_57/checkpoint_500.pth.\n",
      "05/22/2019 15:32:26 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:33:46 - INFO - emmental.logging.checkpointer -   Save checkpoint of 600 batch at logs/2019_05_22/15_23_57/checkpoint_600.pth.\n",
      "05/22/2019 15:33:57 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:35:18 - INFO - emmental.logging.checkpointer -   Save checkpoint of 700 batch at logs/2019_05_22/15_23_57/checkpoint_700.pth.\n",
      "05/22/2019 15:35:29 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:36:48 - INFO - emmental.logging.checkpointer -   Save checkpoint of 800 batch at logs/2019_05_22/15_23_57/checkpoint_800.pth.\n",
      "05/22/2019 15:38:08 - INFO - emmental.logging.checkpointer -   Save checkpoint of 900 batch at logs/2019_05_22/15_23_57/checkpoint_900.pth.\n",
      "05/22/2019 15:38:19 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:39:38 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1000 batch at logs/2019_05_22/15_23_57/checkpoint_1000.pth.\n",
      "05/22/2019 15:39:50 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:41:09 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1100 batch at logs/2019_05_22/15_23_57/checkpoint_1100.pth.\n",
      "05/22/2019 15:42:28 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1200 batch at logs/2019_05_22/15_23_57/checkpoint_1200.pth.\n",
      "05/22/2019 15:42:40 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:43:59 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1300 batch at logs/2019_05_22/15_23_57/checkpoint_1300.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb3f4cddcb3494abe077888b2a58456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 15:45:19 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1400 batch at logs/2019_05_22/15_23_57/checkpoint_1400.pth.\n",
      "05/22/2019 15:45:31 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:46:50 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1500 batch at logs/2019_05_22/15_23_57/checkpoint_1500.pth.\n",
      "05/22/2019 15:48:10 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1600 batch at logs/2019_05_22/15_23_57/checkpoint_1600.pth.\n",
      "05/22/2019 15:48:21 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 15:49:40 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1700 batch at logs/2019_05_22/15_23_57/checkpoint_1700.pth.\n",
      "05/22/2019 15:51:00 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1800 batch at logs/2019_05_22/15_23_57/checkpoint_1800.pth.\n",
      "05/22/2019 15:52:19 - INFO - emmental.logging.checkpointer -   Save checkpoint of 1900 batch at logs/2019_05_22/15_23_57/checkpoint_1900.pth.\n",
      "05/22/2019 15:53:38 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2000 batch at logs/2019_05_22/15_23_57/checkpoint_2000.pth.\n",
      "05/22/2019 15:54:57 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2100 batch at logs/2019_05_22/15_23_57/checkpoint_2100.pth.\n",
      "05/22/2019 15:56:17 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2200 batch at logs/2019_05_22/15_23_57/checkpoint_2200.pth.\n",
      "05/22/2019 15:57:37 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2300 batch at logs/2019_05_22/15_23_57/checkpoint_2300.pth.\n",
      "05/22/2019 15:59:01 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2400 batch at logs/2019_05_22/15_23_57/checkpoint_2400.pth.\n",
      "05/22/2019 16:00:20 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2500 batch at logs/2019_05_22/15_23_57/checkpoint_2500.pth.\n",
      "05/22/2019 16:01:39 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2600 batch at logs/2019_05_22/15_23_57/checkpoint_2600.pth.\n",
      "05/22/2019 16:03:05 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2700 batch at logs/2019_05_22/15_23_57/checkpoint_2700.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c4a44b9d1a48f79344195002898f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 16:04:33 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2800 batch at logs/2019_05_22/15_23_57/checkpoint_2800.pth.\n",
      "05/22/2019 16:06:00 - INFO - emmental.logging.checkpointer -   Save checkpoint of 2900 batch at logs/2019_05_22/15_23_57/checkpoint_2900.pth.\n",
      "05/22/2019 16:06:18 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 16:07:47 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3000 batch at logs/2019_05_22/15_23_57/checkpoint_3000.pth.\n",
      "05/22/2019 16:09:14 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3100 batch at logs/2019_05_22/15_23_57/checkpoint_3100.pth.\n",
      "05/22/2019 16:10:42 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3200 batch at logs/2019_05_22/15_23_57/checkpoint_3200.pth.\n",
      "05/22/2019 16:12:12 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3300 batch at logs/2019_05_22/15_23_57/checkpoint_3300.pth.\n",
      "05/22/2019 16:13:42 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3400 batch at logs/2019_05_22/15_23_57/checkpoint_3400.pth.\n",
      "05/22/2019 16:15:08 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3500 batch at logs/2019_05_22/15_23_57/checkpoint_3500.pth.\n",
      "05/22/2019 16:16:35 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3600 batch at logs/2019_05_22/15_23_57/checkpoint_3600.pth.\n",
      "05/22/2019 16:18:03 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3700 batch at logs/2019_05_22/15_23_57/checkpoint_3700.pth.\n",
      "05/22/2019 16:19:27 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3800 batch at logs/2019_05_22/15_23_57/checkpoint_3800.pth.\n",
      "05/22/2019 16:20:54 - INFO - emmental.logging.checkpointer -   Save checkpoint of 3900 batch at logs/2019_05_22/15_23_57/checkpoint_3900.pth.\n",
      "05/22/2019 16:22:23 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4000 batch at logs/2019_05_22/15_23_57/checkpoint_4000.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f125f3204e4d749428c9296b997738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 16:23:52 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4100 batch at logs/2019_05_22/15_23_57/checkpoint_4100.pth.\n",
      "05/22/2019 16:24:09 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 16:25:39 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4200 batch at logs/2019_05_22/15_23_57/checkpoint_4200.pth.\n",
      "05/22/2019 16:27:07 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4300 batch at logs/2019_05_22/15_23_57/checkpoint_4300.pth.\n",
      "05/22/2019 16:28:37 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4400 batch at logs/2019_05_22/15_23_57/checkpoint_4400.pth.\n",
      "05/22/2019 16:30:06 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4500 batch at logs/2019_05_22/15_23_57/checkpoint_4500.pth.\n",
      "05/22/2019 16:31:37 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4600 batch at logs/2019_05_22/15_23_57/checkpoint_4600.pth.\n",
      "05/22/2019 16:33:07 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4700 batch at logs/2019_05_22/15_23_57/checkpoint_4700.pth.\n",
      "05/22/2019 16:34:36 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4800 batch at logs/2019_05_22/15_23_57/checkpoint_4800.pth.\n",
      "05/22/2019 16:36:08 - INFO - emmental.logging.checkpointer -   Save checkpoint of 4900 batch at logs/2019_05_22/15_23_57/checkpoint_4900.pth.\n",
      "05/22/2019 16:36:23 - INFO - emmental.logging.checkpointer -   Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "05/22/2019 16:37:47 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5000 batch at logs/2019_05_22/15_23_57/checkpoint_5000.pth.\n",
      "05/22/2019 16:39:14 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5100 batch at logs/2019_05_22/15_23_57/checkpoint_5100.pth.\n",
      "05/22/2019 16:40:41 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5200 batch at logs/2019_05_22/15_23_57/checkpoint_5200.pth.\n",
      "05/22/2019 16:42:14 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5300 batch at logs/2019_05_22/15_23_57/checkpoint_5300.pth.\n",
      "05/22/2019 16:43:51 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5400 batch at logs/2019_05_22/15_23_57/checkpoint_5400.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288d433889d644eeb8754c6332a10b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 16:45:20 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5500 batch at logs/2019_05_22/15_23_57/checkpoint_5500.pth.\n",
      "05/22/2019 16:46:47 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5600 batch at logs/2019_05_22/15_23_57/checkpoint_5600.pth.\n",
      "05/22/2019 16:48:18 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5700 batch at logs/2019_05_22/15_23_57/checkpoint_5700.pth.\n",
      "05/22/2019 16:49:51 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5800 batch at logs/2019_05_22/15_23_57/checkpoint_5800.pth.\n",
      "05/22/2019 16:51:24 - INFO - emmental.logging.checkpointer -   Save checkpoint of 5900 batch at logs/2019_05_22/15_23_57/checkpoint_5900.pth.\n",
      "05/22/2019 16:52:56 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6000 batch at logs/2019_05_22/15_23_57/checkpoint_6000.pth.\n",
      "05/22/2019 16:54:29 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6100 batch at logs/2019_05_22/15_23_57/checkpoint_6100.pth.\n",
      "05/22/2019 16:56:04 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6200 batch at logs/2019_05_22/15_23_57/checkpoint_6200.pth.\n",
      "05/22/2019 16:57:37 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6300 batch at logs/2019_05_22/15_23_57/checkpoint_6300.pth.\n",
      "05/22/2019 16:59:07 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6400 batch at logs/2019_05_22/15_23_57/checkpoint_6400.pth.\n",
      "05/22/2019 17:00:35 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6500 batch at logs/2019_05_22/15_23_57/checkpoint_6500.pth.\n",
      "05/22/2019 17:02:10 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6600 batch at logs/2019_05_22/15_23_57/checkpoint_6600.pth.\n",
      "05/22/2019 17:03:43 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6700 batch at logs/2019_05_22/15_23_57/checkpoint_6700.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b8b190872148b1bde37c78c8a3101b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 17:05:18 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6800 batch at logs/2019_05_22/15_23_57/checkpoint_6800.pth.\n",
      "05/22/2019 17:06:51 - INFO - emmental.logging.checkpointer -   Save checkpoint of 6900 batch at logs/2019_05_22/15_23_57/checkpoint_6900.pth.\n",
      "05/22/2019 17:08:31 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7000 batch at logs/2019_05_22/15_23_57/checkpoint_7000.pth.\n",
      "05/22/2019 17:10:07 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7100 batch at logs/2019_05_22/15_23_57/checkpoint_7100.pth.\n",
      "05/22/2019 17:11:43 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7200 batch at logs/2019_05_22/15_23_57/checkpoint_7200.pth.\n",
      "05/22/2019 17:13:13 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7300 batch at logs/2019_05_22/15_23_57/checkpoint_7300.pth.\n",
      "05/22/2019 17:14:39 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7400 batch at logs/2019_05_22/15_23_57/checkpoint_7400.pth.\n",
      "05/22/2019 17:15:59 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7500 batch at logs/2019_05_22/15_23_57/checkpoint_7500.pth.\n",
      "05/22/2019 17:17:17 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7600 batch at logs/2019_05_22/15_23_57/checkpoint_7600.pth.\n",
      "05/22/2019 17:18:37 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7700 batch at logs/2019_05_22/15_23_57/checkpoint_7700.pth.\n",
      "05/22/2019 17:20:00 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7800 batch at logs/2019_05_22/15_23_57/checkpoint_7800.pth.\n",
      "05/22/2019 17:21:21 - INFO - emmental.logging.checkpointer -   Save checkpoint of 7900 batch at logs/2019_05_22/15_23_57/checkpoint_7900.pth.\n",
      "05/22/2019 17:22:43 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8000 batch at logs/2019_05_22/15_23_57/checkpoint_8000.pth.\n",
      "05/22/2019 17:24:02 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8100 batch at logs/2019_05_22/15_23_57/checkpoint_8100.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756038f9d7b1417398ec6bc923654f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 17:25:22 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8200 batch at logs/2019_05_22/15_23_57/checkpoint_8200.pth.\n",
      "05/22/2019 17:26:40 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8300 batch at logs/2019_05_22/15_23_57/checkpoint_8300.pth.\n",
      "05/22/2019 17:28:00 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8400 batch at logs/2019_05_22/15_23_57/checkpoint_8400.pth.\n",
      "05/22/2019 17:29:19 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8500 batch at logs/2019_05_22/15_23_57/checkpoint_8500.pth.\n",
      "05/22/2019 17:30:38 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8600 batch at logs/2019_05_22/15_23_57/checkpoint_8600.pth.\n",
      "05/22/2019 17:31:57 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8700 batch at logs/2019_05_22/15_23_57/checkpoint_8700.pth.\n",
      "05/22/2019 17:33:18 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8800 batch at logs/2019_05_22/15_23_57/checkpoint_8800.pth.\n",
      "05/22/2019 17:34:37 - INFO - emmental.logging.checkpointer -   Save checkpoint of 8900 batch at logs/2019_05_22/15_23_57/checkpoint_8900.pth.\n",
      "05/22/2019 17:35:57 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9000 batch at logs/2019_05_22/15_23_57/checkpoint_9000.pth.\n",
      "05/22/2019 17:37:17 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9100 batch at logs/2019_05_22/15_23_57/checkpoint_9100.pth.\n",
      "05/22/2019 17:38:38 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9200 batch at logs/2019_05_22/15_23_57/checkpoint_9200.pth.\n",
      "05/22/2019 17:39:57 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9300 batch at logs/2019_05_22/15_23_57/checkpoint_9300.pth.\n",
      "05/22/2019 17:41:15 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9400 batch at logs/2019_05_22/15_23_57/checkpoint_9400.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b384ad2c4f948259f61dcadbbb8dbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 17:42:34 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9500 batch at logs/2019_05_22/15_23_57/checkpoint_9500.pth.\n",
      "05/22/2019 17:43:52 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9600 batch at logs/2019_05_22/15_23_57/checkpoint_9600.pth.\n",
      "05/22/2019 17:45:11 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9700 batch at logs/2019_05_22/15_23_57/checkpoint_9700.pth.\n",
      "05/22/2019 17:46:30 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9800 batch at logs/2019_05_22/15_23_57/checkpoint_9800.pth.\n",
      "05/22/2019 17:47:49 - INFO - emmental.logging.checkpointer -   Save checkpoint of 9900 batch at logs/2019_05_22/15_23_57/checkpoint_9900.pth.\n",
      "05/22/2019 17:49:07 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10000 batch at logs/2019_05_22/15_23_57/checkpoint_10000.pth.\n",
      "05/22/2019 17:50:28 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10100 batch at logs/2019_05_22/15_23_57/checkpoint_10100.pth.\n",
      "05/22/2019 17:51:46 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10200 batch at logs/2019_05_22/15_23_57/checkpoint_10200.pth.\n",
      "05/22/2019 17:53:04 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10300 batch at logs/2019_05_22/15_23_57/checkpoint_10300.pth.\n",
      "05/22/2019 17:54:24 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10400 batch at logs/2019_05_22/15_23_57/checkpoint_10400.pth.\n",
      "05/22/2019 17:55:44 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10500 batch at logs/2019_05_22/15_23_57/checkpoint_10500.pth.\n",
      "05/22/2019 17:57:03 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10600 batch at logs/2019_05_22/15_23_57/checkpoint_10600.pth.\n",
      "05/22/2019 17:58:22 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10700 batch at logs/2019_05_22/15_23_57/checkpoint_10700.pth.\n",
      "05/22/2019 17:59:40 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10800 batch at logs/2019_05_22/15_23_57/checkpoint_10800.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76979cc5521b48a189060527209ae44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 18:00:59 - INFO - emmental.logging.checkpointer -   Save checkpoint of 10900 batch at logs/2019_05_22/15_23_57/checkpoint_10900.pth.\n",
      "05/22/2019 18:02:19 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11000 batch at logs/2019_05_22/15_23_57/checkpoint_11000.pth.\n",
      "05/22/2019 18:03:38 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11100 batch at logs/2019_05_22/15_23_57/checkpoint_11100.pth.\n",
      "05/22/2019 18:04:57 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11200 batch at logs/2019_05_22/15_23_57/checkpoint_11200.pth.\n",
      "05/22/2019 18:06:16 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11300 batch at logs/2019_05_22/15_23_57/checkpoint_11300.pth.\n",
      "05/22/2019 18:07:35 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11400 batch at logs/2019_05_22/15_23_57/checkpoint_11400.pth.\n",
      "05/22/2019 18:08:54 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11500 batch at logs/2019_05_22/15_23_57/checkpoint_11500.pth.\n",
      "05/22/2019 18:10:12 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11600 batch at logs/2019_05_22/15_23_57/checkpoint_11600.pth.\n",
      "05/22/2019 18:11:32 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11700 batch at logs/2019_05_22/15_23_57/checkpoint_11700.pth.\n",
      "05/22/2019 18:12:51 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11800 batch at logs/2019_05_22/15_23_57/checkpoint_11800.pth.\n",
      "05/22/2019 18:14:10 - INFO - emmental.logging.checkpointer -   Save checkpoint of 11900 batch at logs/2019_05_22/15_23_57/checkpoint_11900.pth.\n",
      "05/22/2019 18:15:33 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12000 batch at logs/2019_05_22/15_23_57/checkpoint_12000.pth.\n",
      "05/22/2019 18:16:52 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12100 batch at logs/2019_05_22/15_23_57/checkpoint_12100.pth.\n",
      "05/22/2019 18:18:10 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12200 batch at logs/2019_05_22/15_23_57/checkpoint_12200.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b680b47c7444ad98cd35ab633d5280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 18:19:29 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12300 batch at logs/2019_05_22/15_23_57/checkpoint_12300.pth.\n",
      "05/22/2019 18:20:47 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12400 batch at logs/2019_05_22/15_23_57/checkpoint_12400.pth.\n",
      "05/22/2019 18:22:06 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12500 batch at logs/2019_05_22/15_23_57/checkpoint_12500.pth.\n",
      "05/22/2019 18:23:29 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12600 batch at logs/2019_05_22/15_23_57/checkpoint_12600.pth.\n",
      "05/22/2019 18:24:49 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12700 batch at logs/2019_05_22/15_23_57/checkpoint_12700.pth.\n",
      "05/22/2019 18:26:07 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12800 batch at logs/2019_05_22/15_23_57/checkpoint_12800.pth.\n",
      "05/22/2019 18:27:26 - INFO - emmental.logging.checkpointer -   Save checkpoint of 12900 batch at logs/2019_05_22/15_23_57/checkpoint_12900.pth.\n",
      "05/22/2019 18:28:46 - INFO - emmental.logging.checkpointer -   Save checkpoint of 13000 batch at logs/2019_05_22/15_23_57/checkpoint_13000.pth.\n",
      "05/22/2019 18:30:11 - INFO - emmental.logging.checkpointer -   Save checkpoint of 13100 batch at logs/2019_05_22/15_23_57/checkpoint_13100.pth.\n",
      "05/22/2019 18:31:31 - INFO - emmental.logging.checkpointer -   Save checkpoint of 13200 batch at logs/2019_05_22/15_23_57/checkpoint_13200.pth.\n",
      "05/22/2019 18:32:49 - INFO - emmental.logging.checkpointer -   Save checkpoint of 13300 batch at logs/2019_05_22/15_23_57/checkpoint_13300.pth.\n",
      "05/22/2019 18:34:09 - INFO - emmental.logging.checkpointer -   Save checkpoint of 13400 batch at logs/2019_05_22/15_23_57/checkpoint_13400.pth.\n",
      "05/22/2019 18:35:28 - INFO - emmental.logging.checkpointer -   Save checkpoint of 13500 batch at logs/2019_05_22/15_23_57/checkpoint_13500.pth.\n",
      "05/22/2019 18:36:03 - INFO - emmental.logging.checkpointer -   Clear all immediate checkpoints.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/22/2019 18:37:04 - INFO - emmental.logging.checkpointer -   Loading the best model from logs/2019_05_22/15_23_57/best_model_WiC_SuperGLUE_val_accuracy.pth.\n",
      "05/22/2019 18:37:07 - INFO - emmental.model -   Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "emmental_learner.learn(mtl_model, dataloaders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pytorch_pretrained_bert failed: Traceback (most recent call last):\n",
      "  File \"/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/pytorch_pretrained_bert/__init__.py\", line 7, in <module>\n",
      "    from .modeling import (BertConfig, BertModel, BertForPreTraining,\n",
      "ImportError: cannot import name 'BertForMultipleChoice'\n",
      "]\n",
      "05/22/2019 18:37:08 - INFO - pytorch_pretrained_bert.modeling -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BertLayerNorm' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f8128500b396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmtl_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch1/senwu/mmtl/emmental/src/emmental/model.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, dataloaders)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             gold_dict, prob_dict, pred_dict = self.predict(\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             )\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgold_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch1/senwu/mmtl/emmental/src/emmental/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, dataloader, return_preds)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             prob_batch_dict = self._calculate_probs(\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mX_batch_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_to_label_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             )\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_to_label_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch1/senwu/mmtl/emmental/src/emmental/model.py\u001b[0m in \u001b[0;36m_calculate_probs\u001b[0;34m(self, X_dict, task_names)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mprob_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mimmediate_ouput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# Calculate prediction for each task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch1/senwu/mmtl/emmental/src/emmental/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_dict, task_names)\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unrecognized action {action}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_pool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                         output = self.module_pool[action[\"module\"]].forward(\n",
      "\u001b[0;32m/dfs/scratch1/senwu/mmtl/emmental-tutorials/superglue/modules/bert_module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, token_segments)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0mextended_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwords_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBertEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 539\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertLayerNorm' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_model.score(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_model.module_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model1 = EmmentalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model1.load(\"logs/2019_05_20/17_58_01/best_model_WiC_SuperGLUE_val_accuracy.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# res_dict = mtl_model.predict(dataloaders[\"val\"], return_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# res_dict_golds, res_dict_probs, res_dict_preds = res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# res_dict_golds[\"WiC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_dict_probs[\"WiC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_dict_preds[\"WiC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot = 0\n",
    "# for g, p in zip(res_dict_golds[\"WiC\"], res_dict_preds[\"WiC\"]):\n",
    "#     if g == p:\n",
    "#         tot += 1\n",
    "# print(tot/len(res_dict_golds[\"WiC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset = dataloaders[\"val\"].dataset\n",
    "\n",
    "# for idx in range(len(dataloaders[\"val\"].dataset)):\n",
    "#     if res_dict_golds[\"WiC\"][idx] != res_dict_preds[\"WiC\"][idx]:\n",
    "#         print(\"####\".join([\n",
    "#             str(idx),\n",
    "#             \"True\" if res_dict_golds[\"WiC\"][idx] == 1 else \"False\",\n",
    "#             dataset.X_dict[\"words\"][idx],\n",
    "#             dataset.X_dict[\"poses\"][idx],\n",
    "#             dataset.X_dict[\"sent1\"][idx],\n",
    "#             str(dataset.X_dict[\"sent1_idxs\"][idx].item()),\n",
    "#             dataset.X_dict[\"sent2\"][idx],\n",
    "#             str(dataset.X_dict[\"sent2_idxs\"][idx].item()),\n",
    "#         ])\n",
    "#         )\n",
    "# #     print(dataloaders[\"val\"].dataset.Y_dict[\"labels\"][idx].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
