{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from parse_WiC_slice import get_WiC_dataloaders\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:46:58,445][INFO] emmental.meta:95 - Setting logging directory to: logs/2019_05_30/13_46_58\n",
      "[2019-05-30 13:46:58,455][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch0/bradenjh/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-05-30 13:46:58,456][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 10,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\"warmup_percentage\": 0.1, \"lr_scheduler\": None},\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 100,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\"checkpoint_metric\": {\"WiC/SuperGLUE/val/accuracy\":\"max\"}},\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta_config': {'seed': 0, 'verbose': True, 'log_path': None},\n",
       " 'model_config': {'model_path': None, 'device': 0, 'dataparallel': False},\n",
       " 'learner_config': {'fp16': False,\n",
       "  'n_epochs': 10,\n",
       "  'train_split': 'train',\n",
       "  'valid_split': 'val',\n",
       "  'test_split': 'test',\n",
       "  'ignore_index': -100,\n",
       "  'optimizer_config': {'optimizer': 'adam',\n",
       "   'lr': 1e-05,\n",
       "   'l2': 0.0,\n",
       "   'grad_clip': 1.0,\n",
       "   'sgd_config': {'momentum': 0.9},\n",
       "   'adam_config': {'betas': (0.9, 0.999)}},\n",
       "  'lr_scheduler_config': {'lr_scheduler': None,\n",
       "   'warmup_steps': None,\n",
       "   'warmup_unit': 'batch',\n",
       "   'warmup_percentage': 0.1,\n",
       "   'min_lr': 0.0,\n",
       "   'linear_config': {'min_lr': 0.0},\n",
       "   'exponential_config': {'gamma': 0.9},\n",
       "   'plateau_config': {'factor': 0.5, 'patience': 10, 'threshold': 0.0001}},\n",
       "  'task_scheduler': 'round_robin',\n",
       "  'global_evaluation_metric_dict': None,\n",
       "  'min_lr': 0},\n",
       " 'logging_config': {'counter_unit': 'batch',\n",
       "  'evaluation_freq': 100,\n",
       "  'writer_config': {'writer': 'tensorboard', 'verbose': True},\n",
       "  'checkpointing': True,\n",
       "  'checkpointer_config': {'checkpoint_path': None,\n",
       "   'checkpoint_freq': 1,\n",
       "   'checkpoint_metric': {'WiC/SuperGLUE/val/accuracy': 'max'},\n",
       "   'checkpoint_task_metrics': None,\n",
       "   'checkpoint_runway': 0,\n",
       "   'checkpoint_clear': True}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TASK_NAME = \"WiC\"\n",
    "DATA_DIR = os.environ[\"SUPERGLUEDATA\"]\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_OUTPUT_DIM, TASK_CARDINALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_verb(dataset):\n",
    "    slice_name = \"slice_verb\"\n",
    "    ind, pred = [], []\n",
    "    cnt = 0\n",
    "    for idx, pos in enumerate(dataset.X_dict[\"poses\"]):\n",
    "        if pos == \"V\":\n",
    "            ind.append(1)\n",
    "            pred.append(dataset.Y_dict[\"labels\"][idx])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ind.append(2)\n",
    "            pred.append(Meta.config[\"learner_config\"][\"ignore_index\"])\n",
    "    ind = torch.from_numpy(np.array(ind)).view(-1)\n",
    "    pred = torch.from_numpy(np.array(pred)).view(-1)\n",
    "    logger.info(f\"Total {cnt} / {len(dataset)} in the slice {slice_name}\")\n",
    "    print(ind.size(), pred.size())\n",
    "    return ind, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_noun(dataset):\n",
    "    slice_name = \"slice_noun\"\n",
    "    ind, pred = [], []\n",
    "    cnt = 0\n",
    "    for idx, pos in enumerate(dataset.X_dict[\"poses\"]):\n",
    "        if pos == \"N\":\n",
    "            ind.append(1)\n",
    "            pred.append(dataset.Y_dict[\"labels\"][idx])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ind.append(2)\n",
    "            pred.append(Meta.config[\"learner_config\"][\"ignore_index\"])\n",
    "    ind = torch.from_numpy(np.array(ind)).view(-1)\n",
    "    pred = torch.from_numpy(np.array(pred)).view(-1)\n",
    "    logger.info(f\"Total {cnt} / {len(dataset)} in the slice {slice_name}\")\n",
    "    print(ind.size(), pred.size())\n",
    "    return ind, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_first_pos(dataset):\n",
    "    slice_name = \"slice_first_pos\"\n",
    "    ind, pred = [], []\n",
    "    cnt = 0\n",
    "    for idx, pos in enumerate(dataset.X_dict[\"poses\"]):\n",
    "        if dataset.X_dict[\"sent1_ori_idxs\"][idx] == 1 and dataset.X_dict[\"sent2_ori_idxs\"][idx] == 1:\n",
    "            ind.append(1)\n",
    "            pred.append(dataset.Y_dict[\"labels\"][idx])\n",
    "            cnt += 1\n",
    "        else:\n",
    "            ind.append(2)\n",
    "            pred.append(Meta.config[\"learner_config\"][\"ignore_index\"])\n",
    "    ind = torch.from_numpy(np.array(ind)).view(-1)\n",
    "    pred = torch.from_numpy(np.array(pred)).view(-1)\n",
    "    logger.info(f\"Total {cnt} / {len(dataset)} in the slice {slice_name}\")\n",
    "    print(ind.size(), pred.size())\n",
    "    return ind, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_base(dataset):\n",
    "    return torch.from_numpy(np.array([1] * len(dataset))), dataset.Y_dict[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['slice_base', 'slice_verb'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_func_dict = {\n",
    "    \"slice_base\": slice_base,\n",
    "    \"slice_verb\": slice_verb,\n",
    "#     \"slice_noun\": slice_noun,\n",
    "#     \"slice_first_pos\": slice_first_pos,\n",
    "}\n",
    "slice_func_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:47:40,123][INFO] tokenizer:8 - Loading Tokenizer bert-large-cased\n",
      "[2019-05-30 13:47:40,385][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /afs/cs.stanford.edu/u/bradenjh/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "[2019-05-30 13:47:42,403][INFO] __main__:15 - Total 2634 / 5428 in the slice slice_verb\n",
      "[2019-05-30 13:47:42,404][INFO] parse_WiC_slice:181 - Loaded train for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 68\n",
      "torch.Size([5428]) torch.Size([5428])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:47:42,646][INFO] __main__:15 - Total 243 / 638 in the slice slice_verb\n",
      "[2019-05-30 13:47:42,646][INFO] parse_WiC_slice:181 - Loaded val for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 57\n",
      "torch.Size([638]) torch.Size([638])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:47:43,183][INFO] __main__:15 - Total 569 / 1400 in the slice slice_verb\n",
      "[2019-05-30 13:47:43,184][INFO] parse_WiC_slice:181 - Loaded test for WiC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 60\n",
      "torch.Size([1400]) torch.Size([1400])\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_WiC_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\", \"test\"],\n",
    "    max_sequence_length=128,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    slice_func_dict=slice_func_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([2, 2, 2,  ..., 1, 1, 1]),\n",
       " 'WiC_slice_ind_slice_base': tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
       " 'WiC_slice_pred_slice_base': tensor([2, 2, 2,  ..., 1, 1, 1]),\n",
       " 'WiC_slice_ind_slice_verb': tensor([1, 1, 1,  ..., 1, 1, 2]),\n",
       " 'WiC_slice_pred_slice_verb': tensor([   2,    2,    2,  ...,    1,    1, -100])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders[\"train\"].dataset.Y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WiC_slice_ind_slice_base': 'WiC_slice_ind_slice_base',\n",
       " 'WiC_slice_pred_slice_base': 'WiC_slice_pred_slice_base',\n",
       " 'WiC_slice_ind_slice_verb': 'WiC_slice_ind_slice_verb',\n",
       " 'WiC_slice_pred_slice_verb': 'WiC_slice_pred_slice_verb',\n",
       " 'WiC': 'labels'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders[\"train\"].task_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels torch.Size([5428])\n",
      "WiC_slice_ind_slice_base torch.Size([5428])\n",
      "WiC_slice_pred_slice_base torch.Size([5428])\n",
      "WiC_slice_ind_slice_verb torch.Size([5428])\n",
      "WiC_slice_pred_slice_verb torch.Size([5428])\n"
     ]
    }
   ],
   "source": [
    "for key, value in dataloaders[\"train\"].dataset.Y_dict.items():\n",
    "    print(key, value.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(module_name, immediate_ouput_dict, Y, active):\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(module_name, immediate_ouput_dict):\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureConcateModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, feature, idx1, idx2):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        last_layer = feature[-1]\n",
    "        emb = last_layer[:,0,:]\n",
    "        idx1 = idx1.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        idx2 = idx2.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        word1_emb = last_layer.gather(dim=1, index=idx1).squeeze(dim=1)\n",
    "        word2_emb = last_layer.gather(dim=1, index=idx2).squeeze(dim=1)\n",
    "        input = torch.cat([emb, word1_emb, word2_emb], dim=-1)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        return self.linear.forward(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = BERT_OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_classification_module = nn.Linear(H, TASK_CARDINALITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:47:51,470][INFO] pytorch_pretrained_bert.modeling:580 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "[2019-05-30 13:47:51,471][INFO] pytorch_pretrained_bert.modeling:588 - extracting archive file ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpchqebob3\n",
      "[2019-05-30 13:48:03,606][INFO] pytorch_pretrained_bert.modeling:598 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_module = BertModule(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:48:13,281][INFO] emmental.task:34 - Created task: WiC_slice_ind_slice_base\n",
      "[2019-05-30 13:48:13,282][INFO] emmental.task:34 - Created task: WiC_slice_ind_slice_verb\n"
     ]
    }
   ],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"ind\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": SliceModule(\n",
    "                    3 * BERT_OUTPUT_DIM, 2\n",
    "                ),\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"feature\",\n",
    "                \"module\": f\"feature\",\n",
    "                \"inputs\": [\n",
    "                    (\"input\", 0),\n",
    "                    (\"_input_\", \"sent1_idxs\"),\n",
    "                    (\"_input_\", \"sent2_idxs\"),\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(metrics=[\"accuracy\"]),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:48:13,350][INFO] emmental.task:34 - Created task: WiC_slice_pred_slice_base\n",
      "[2019-05-30 13:48:13,380][INFO] emmental.task:34 - Created task: WiC_slice_pred_slice_verb\n"
     ]
    }
   ],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"pred\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_feat_{slice_name}\": nn.Linear(3 * BERT_OUTPUT_DIM, H),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": shared_classification_module,\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"feature\",\n",
    "                \"module\": f\"feature\",\n",
    "                \"inputs\": [\n",
    "                    (\"input\", 0),\n",
    "                    (\"_input_\", \"sent1_idxs\"),\n",
    "                    (\"_input_\", \"sent2_idxs\"),\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(f\"{TASK_NAME}_slice_feat_{slice_name}\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, immediate_ouput_dict):\n",
    "        slice_ind_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_ind_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "        slice_pred_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_pred_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        Q = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_ind_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_ind_name in slice_ind_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        P = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_pred_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_pred_name in slice_pred_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        slice_feat_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_feat_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        slice_reps = torch.cat(\n",
    "            [\n",
    "                immediate_ouput_dict[slice_feat_name][0].unsqueeze(1)\n",
    "                for slice_feat_name in slice_feat_names\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        A = F.softmax(Q * P, dim=1).unsqueeze(-1).expand([-1, -1, slice_reps.size(-1)])\n",
    "\n",
    "        reweighted_rep = torch.sum(A * slice_reps, 1)\n",
    "\n",
    "        return self.linear.forward(reweighted_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:48:13,447][INFO] emmental.task:34 - Created task: WiC\n"
     ]
    }
   ],
   "source": [
    "master_task = EmmentalTask(\n",
    "    name=f\"{TASK_NAME}\",\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": bert_module,\n",
    "            f\"{TASK_NAME}_pred_head\": MasterModule(H, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [],\n",
    "        }\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, f\"{TASK_NAME}_pred_head\"),\n",
    "    output_func=partial(output, f\"{TASK_NAME}_pred_head\"),\n",
    "    scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    ")\n",
    "tasks.append(master_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:48:13,486][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-05-30 13:48:16,602][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-05-30 13:48:16,604][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-05-30 13:48:16,609][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-05-30 13:48:16,614][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-05-30 13:48:17,024][INFO] emmental.model:44 - Created emmental model SuperGLUE_single_task that contains task {'WiC_slice_ind_slice_base', 'WiC', 'WiC_slice_ind_slice_verb', 'WiC_slice_pred_slice_verb', 'WiC_slice_pred_slice_base'}.\n",
      "[2019-05-30 13:48:17,025][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for X, Y in dataloaders[\"train\"]:\n",
    "#     import pdb; pdb.set_trace()\n",
    "# # #     print(X, Y)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 13:48:17,144][INFO] emmental.logging.logging_manager:33 - Evaluating every 100 batch.\n",
      "[2019-05-30 13:48:17,145][INFO] emmental.logging.logging_manager:43 - Checkpointing every 100 batch.\n",
      "[2019-05-30 13:48:17,146][INFO] emmental.logging.checkpointer:42 - Save checkpoints at logs/2019_05_30/13_46_58 every 100 batch\n",
      "[2019-05-30 13:48:17,146][INFO] emmental.logging.checkpointer:73 - No checkpoints saved before 0 batch.\n",
      "[2019-05-30 13:48:17,171][INFO] emmental.learner:152 - Warmup 1357 batchs.\n",
      "[2019-05-30 13:48:17,174][INFO] emmental.learner:303 - Start learning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666a3cca97ec405aada5ae2063f2aa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "[2019-05-30 13:49:01,155][INFO] emmental.logging.checkpointer:93 - checkpoint_runway condition has been met. Start checkpoining.\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type SliceModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type FeatureConcateModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MasterModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "[2019-05-30 13:49:12,499][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 100 batch at logs/2019_05_30/13_46_58/checkpoint_100.pth.\n",
      "[2019-05-30 13:49:23,652][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 13:50:18,929][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 200 batch at logs/2019_05_30/13_46_58/checkpoint_200.pth.\n",
      "[2019-05-30 13:51:15,175][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 300 batch at logs/2019_05_30/13_46_58/checkpoint_300.pth.\n",
      "[2019-05-30 13:51:27,939][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 13:52:27,456][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 400 batch at logs/2019_05_30/13_46_58/checkpoint_400.pth.\n",
      "[2019-05-30 13:52:38,464][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 13:53:33,862][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 500 batch at logs/2019_05_30/13_46_58/checkpoint_500.pth.\n",
      "[2019-05-30 13:53:45,865][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 13:54:41,189][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 600 batch at logs/2019_05_30/13_46_58/checkpoint_600.pth.\n",
      "[2019-05-30 13:54:53,425][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 13:55:48,111][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 700 batch at logs/2019_05_30/13_46_58/checkpoint_700.pth.\n",
      "[2019-05-30 13:56:45,622][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 800 batch at logs/2019_05_30/13_46_58/checkpoint_800.pth.\n",
      "[2019-05-30 13:57:46,415][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 900 batch at logs/2019_05_30/13_46_58/checkpoint_900.pth.\n",
      "[2019-05-30 13:58:45,760][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1000 batch at logs/2019_05_30/13_46_58/checkpoint_1000.pth.\n",
      "[2019-05-30 13:58:58,532][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 13:59:56,461][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1100 batch at logs/2019_05_30/13_46_58/checkpoint_1100.pth.\n",
      "[2019-05-30 14:01:03,836][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1200 batch at logs/2019_05_30/13_46_58/checkpoint_1200.pth.\n",
      "[2019-05-30 14:02:04,302][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1300 batch at logs/2019_05_30/13_46_58/checkpoint_1300.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096d2c41ada642c3b7f7d86c2a49f110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 14:03:03,524][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1400 batch at logs/2019_05_30/13_46_58/checkpoint_1400.pth.\n",
      "[2019-05-30 14:03:15,056][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 14:04:10,254][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1500 batch at logs/2019_05_30/13_46_58/checkpoint_1500.pth.\n",
      "[2019-05-30 14:05:05,210][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1600 batch at logs/2019_05_30/13_46_58/checkpoint_1600.pth.\n",
      "[2019-05-30 14:05:17,206][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 14:06:12,115][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1700 batch at logs/2019_05_30/13_46_58/checkpoint_1700.pth.\n",
      "[2019-05-30 14:07:11,129][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1800 batch at logs/2019_05_30/13_46_58/checkpoint_1800.pth.\n",
      "[2019-05-30 14:08:07,305][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 1900 batch at logs/2019_05_30/13_46_58/checkpoint_1900.pth.\n",
      "[2019-05-30 14:08:19,799][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 14:09:18,201][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2000 batch at logs/2019_05_30/13_46_58/checkpoint_2000.pth.\n",
      "[2019-05-30 14:10:16,161][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2100 batch at logs/2019_05_30/13_46_58/checkpoint_2100.pth.\n",
      "[2019-05-30 14:11:12,404][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2200 batch at logs/2019_05_30/13_46_58/checkpoint_2200.pth.\n",
      "[2019-05-30 14:12:08,199][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2300 batch at logs/2019_05_30/13_46_58/checkpoint_2300.pth.\n",
      "[2019-05-30 14:13:04,082][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2400 batch at logs/2019_05_30/13_46_58/checkpoint_2400.pth.\n",
      "[2019-05-30 14:15:13,303][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2600 batch at logs/2019_05_30/13_46_58/checkpoint_2600.pth.\n",
      "[2019-05-30 14:16:15,010][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2700 batch at logs/2019_05_30/13_46_58/checkpoint_2700.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193f0d5c01334633b75bf3654f215201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 14:17:13,565][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2800 batch at logs/2019_05_30/13_46_58/checkpoint_2800.pth.\n",
      "[2019-05-30 14:18:13,091][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 2900 batch at logs/2019_05_30/13_46_58/checkpoint_2900.pth.\n",
      "[2019-05-30 14:18:26,743][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 14:19:25,571][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3000 batch at logs/2019_05_30/13_46_58/checkpoint_3000.pth.\n",
      "[2019-05-30 14:20:26,100][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3100 batch at logs/2019_05_30/13_46_58/checkpoint_3100.pth.\n",
      "[2019-05-30 14:21:25,365][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3200 batch at logs/2019_05_30/13_46_58/checkpoint_3200.pth.\n",
      "[2019-05-30 14:22:20,713][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3300 batch at logs/2019_05_30/13_46_58/checkpoint_3300.pth.\n",
      "[2019-05-30 14:22:35,083][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 14:23:34,676][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3400 batch at logs/2019_05_30/13_46_58/checkpoint_3400.pth.\n",
      "[2019-05-30 14:24:33,583][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3500 batch at logs/2019_05_30/13_46_58/checkpoint_3500.pth.\n",
      "[2019-05-30 14:25:30,049][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3600 batch at logs/2019_05_30/13_46_58/checkpoint_3600.pth.\n",
      "[2019-05-30 14:26:28,652][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3700 batch at logs/2019_05_30/13_46_58/checkpoint_3700.pth.\n",
      "[2019-05-30 14:27:26,156][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3800 batch at logs/2019_05_30/13_46_58/checkpoint_3800.pth.\n",
      "[2019-05-30 14:28:26,959][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 3900 batch at logs/2019_05_30/13_46_58/checkpoint_3900.pth.\n",
      "[2019-05-30 14:29:26,468][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4000 batch at logs/2019_05_30/13_46_58/checkpoint_4000.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f818eda3e244eb8558f892945c7ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 14:30:23,806][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4100 batch at logs/2019_05_30/13_46_58/checkpoint_4100.pth.\n",
      "[2019-05-30 14:31:24,724][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4200 batch at logs/2019_05_30/13_46_58/checkpoint_4200.pth.\n",
      "[2019-05-30 14:32:21,643][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4300 batch at logs/2019_05_30/13_46_58/checkpoint_4300.pth.\n",
      "[2019-05-30 14:32:33,105][INFO] emmental.logging.checkpointer:118 - Save best model of metric WiC/SuperGLUE/val/accuracy at logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-30 14:33:33,375][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4400 batch at logs/2019_05_30/13_46_58/checkpoint_4400.pth.\n",
      "[2019-05-30 14:34:31,104][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4500 batch at logs/2019_05_30/13_46_58/checkpoint_4500.pth.\n",
      "[2019-05-30 14:35:25,183][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4600 batch at logs/2019_05_30/13_46_58/checkpoint_4600.pth.\n",
      "[2019-05-30 14:36:19,039][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4700 batch at logs/2019_05_30/13_46_58/checkpoint_4700.pth.\n",
      "[2019-05-30 14:37:13,675][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4800 batch at logs/2019_05_30/13_46_58/checkpoint_4800.pth.\n",
      "[2019-05-30 14:38:11,685][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 4900 batch at logs/2019_05_30/13_46_58/checkpoint_4900.pth.\n",
      "[2019-05-30 14:39:10,352][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5000 batch at logs/2019_05_30/13_46_58/checkpoint_5000.pth.\n",
      "[2019-05-30 14:40:07,898][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5100 batch at logs/2019_05_30/13_46_58/checkpoint_5100.pth.\n",
      "[2019-05-30 14:41:08,966][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5200 batch at logs/2019_05_30/13_46_58/checkpoint_5200.pth.\n",
      "[2019-05-30 14:42:07,568][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5300 batch at logs/2019_05_30/13_46_58/checkpoint_5300.pth.\n",
      "[2019-05-30 14:43:05,163][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5400 batch at logs/2019_05_30/13_46_58/checkpoint_5400.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253d0260e7af4360a42fa83d46459fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 14:44:01,585][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5500 batch at logs/2019_05_30/13_46_58/checkpoint_5500.pth.\n",
      "[2019-05-30 14:44:57,699][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5600 batch at logs/2019_05_30/13_46_58/checkpoint_5600.pth.\n",
      "[2019-05-30 14:45:56,293][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5700 batch at logs/2019_05_30/13_46_58/checkpoint_5700.pth.\n",
      "[2019-05-30 14:46:56,476][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5800 batch at logs/2019_05_30/13_46_58/checkpoint_5800.pth.\n",
      "[2019-05-30 14:47:55,990][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 5900 batch at logs/2019_05_30/13_46_58/checkpoint_5900.pth.\n",
      "[2019-05-30 14:48:55,515][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6000 batch at logs/2019_05_30/13_46_58/checkpoint_6000.pth.\n",
      "[2019-05-30 14:49:55,455][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6100 batch at logs/2019_05_30/13_46_58/checkpoint_6100.pth.\n",
      "[2019-05-30 14:51:52,788][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6300 batch at logs/2019_05_30/13_46_58/checkpoint_6300.pth.\n",
      "[2019-05-30 14:52:50,467][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6400 batch at logs/2019_05_30/13_46_58/checkpoint_6400.pth.\n",
      "[2019-05-30 14:53:48,027][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6500 batch at logs/2019_05_30/13_46_58/checkpoint_6500.pth.\n",
      "[2019-05-30 14:54:45,466][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6600 batch at logs/2019_05_30/13_46_58/checkpoint_6600.pth.\n",
      "[2019-05-30 14:55:42,680][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6700 batch at logs/2019_05_30/13_46_58/checkpoint_6700.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8123df98a8754d379ad8c6ea41d07a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 14:56:42,840][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6800 batch at logs/2019_05_30/13_46_58/checkpoint_6800.pth.\n",
      "[2019-05-30 14:57:44,519][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 6900 batch at logs/2019_05_30/13_46_58/checkpoint_6900.pth.\n",
      "[2019-05-30 14:58:44,040][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 7000 batch at logs/2019_05_30/13_46_58/checkpoint_7000.pth.\n",
      "[2019-05-30 14:59:42,339][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 7100 batch at logs/2019_05_30/13_46_58/checkpoint_7100.pth.\n",
      "[2019-05-30 15:00:42,127][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 7200 batch at logs/2019_05_30/13_46_58/checkpoint_7200.pth.\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "[2019-05-30 15:08:40,616][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8000 batch at logs/2019_05_30/13_46_58/checkpoint_8000.pth.\n",
      "[2019-05-30 15:09:37,473][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8100 batch at logs/2019_05_30/13_46_58/checkpoint_8100.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53d15bbb64b4cde968296a77c714fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 15:10:34,148][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8200 batch at logs/2019_05_30/13_46_58/checkpoint_8200.pth.\n",
      "[2019-05-30 15:11:32,030][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8300 batch at logs/2019_05_30/13_46_58/checkpoint_8300.pth.\n",
      "[2019-05-30 15:12:28,645][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8400 batch at logs/2019_05_30/13_46_58/checkpoint_8400.pth.\n",
      "[2019-05-30 15:13:22,082][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8500 batch at logs/2019_05_30/13_46_58/checkpoint_8500.pth.\n",
      "[2019-05-30 15:14:16,187][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8600 batch at logs/2019_05_30/13_46_58/checkpoint_8600.pth.\n",
      "[2019-05-30 15:15:11,691][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8700 batch at logs/2019_05_30/13_46_58/checkpoint_8700.pth.\n",
      "[2019-05-30 15:16:08,689][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8800 batch at logs/2019_05_30/13_46_58/checkpoint_8800.pth.\n",
      "[2019-05-30 15:17:05,580][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 8900 batch at logs/2019_05_30/13_46_58/checkpoint_8900.pth.\n",
      "[2019-05-30 15:18:00,708][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9000 batch at logs/2019_05_30/13_46_58/checkpoint_9000.pth.\n",
      "[2019-05-30 15:18:56,311][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9100 batch at logs/2019_05_30/13_46_58/checkpoint_9100.pth.\n",
      "[2019-05-30 15:19:51,949][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9200 batch at logs/2019_05_30/13_46_58/checkpoint_9200.pth.\n",
      "[2019-05-30 15:20:47,795][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9300 batch at logs/2019_05_30/13_46_58/checkpoint_9300.pth.\n",
      "[2019-05-30 15:21:44,628][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9400 batch at logs/2019_05_30/13_46_58/checkpoint_9400.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e06d448de447ab90a4906c5d19c59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 15:22:43,173][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9500 batch at logs/2019_05_30/13_46_58/checkpoint_9500.pth.\n",
      "[2019-05-30 15:23:43,294][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9600 batch at logs/2019_05_30/13_46_58/checkpoint_9600.pth.\n",
      "[2019-05-30 15:24:44,282][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9700 batch at logs/2019_05_30/13_46_58/checkpoint_9700.pth.\n",
      "[2019-05-30 15:25:42,962][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9800 batch at logs/2019_05_30/13_46_58/checkpoint_9800.pth.\n",
      "[2019-05-30 15:26:42,143][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 9900 batch at logs/2019_05_30/13_46_58/checkpoint_9900.pth.\n",
      "[2019-05-30 15:27:41,674][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10000 batch at logs/2019_05_30/13_46_58/checkpoint_10000.pth.\n",
      "[2019-05-30 15:28:40,879][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10100 batch at logs/2019_05_30/13_46_58/checkpoint_10100.pth.\n",
      "[2019-05-30 15:29:38,033][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10200 batch at logs/2019_05_30/13_46_58/checkpoint_10200.pth.\n",
      "[2019-05-30 15:30:33,990][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10300 batch at logs/2019_05_30/13_46_58/checkpoint_10300.pth.\n",
      "[2019-05-30 15:31:32,107][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10400 batch at logs/2019_05_30/13_46_58/checkpoint_10400.pth.\n",
      "[2019-05-30 15:32:31,727][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10500 batch at logs/2019_05_30/13_46_58/checkpoint_10500.pth.\n",
      "[2019-05-30 15:33:33,479][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10600 batch at logs/2019_05_30/13_46_58/checkpoint_10600.pth.\n",
      "[2019-05-30 15:34:30,517][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10700 batch at logs/2019_05_30/13_46_58/checkpoint_10700.pth.\n",
      "[2019-05-30 15:35:30,702][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10800 batch at logs/2019_05_30/13_46_58/checkpoint_10800.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c120ee539d914563bbd860cae186dc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 15:36:28,352][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 10900 batch at logs/2019_05_30/13_46_58/checkpoint_10900.pth.\n",
      "[2019-05-30 15:37:22,819][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11000 batch at logs/2019_05_30/13_46_58/checkpoint_11000.pth.\n",
      "[2019-05-30 15:38:19,116][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11100 batch at logs/2019_05_30/13_46_58/checkpoint_11100.pth.\n",
      "[2019-05-30 15:39:15,441][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11200 batch at logs/2019_05_30/13_46_58/checkpoint_11200.pth.\n",
      "[2019-05-30 15:40:13,208][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11300 batch at logs/2019_05_30/13_46_58/checkpoint_11300.pth.\n",
      "[2019-05-30 15:41:12,215][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11400 batch at logs/2019_05_30/13_46_58/checkpoint_11400.pth.\n",
      "[2019-05-30 15:42:11,547][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11500 batch at logs/2019_05_30/13_46_58/checkpoint_11500.pth.\n",
      "[2019-05-30 15:43:12,043][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11600 batch at logs/2019_05_30/13_46_58/checkpoint_11600.pth.\n",
      "[2019-05-30 15:44:08,565][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11700 batch at logs/2019_05_30/13_46_58/checkpoint_11700.pth.\n",
      "[2019-05-30 15:45:11,059][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11800 batch at logs/2019_05_30/13_46_58/checkpoint_11800.pth.\n",
      "[2019-05-30 15:46:09,937][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 11900 batch at logs/2019_05_30/13_46_58/checkpoint_11900.pth.\n",
      "[2019-05-30 15:47:08,930][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12000 batch at logs/2019_05_30/13_46_58/checkpoint_12000.pth.\n",
      "[2019-05-30 15:48:36,201][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12100 batch at logs/2019_05_30/13_46_58/checkpoint_12100.pth.\n",
      "[2019-05-30 15:50:32,660][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12200 batch at logs/2019_05_30/13_46_58/checkpoint_12200.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c113389fcb240a9a73ec56f0acad994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9:', max=1357, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 15:51:32,341][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12300 batch at logs/2019_05_30/13_46_58/checkpoint_12300.pth.\n",
      "[2019-05-30 15:52:31,766][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12400 batch at logs/2019_05_30/13_46_58/checkpoint_12400.pth.\n",
      "[2019-05-30 15:53:30,391][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12500 batch at logs/2019_05_30/13_46_58/checkpoint_12500.pth.\n",
      "[2019-05-30 15:54:28,461][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12600 batch at logs/2019_05_30/13_46_58/checkpoint_12600.pth.\n",
      "[2019-05-30 15:55:29,440][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12700 batch at logs/2019_05_30/13_46_58/checkpoint_12700.pth.\n",
      "[2019-05-30 15:56:28,761][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 12800 batch at logs/2019_05_30/13_46_58/checkpoint_12800.pth.\n",
      "[2019-05-30 16:00:28,776][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 13200 batch at logs/2019_05_30/13_46_58/checkpoint_13200.pth.\n",
      "[2019-05-30 16:01:28,819][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 13300 batch at logs/2019_05_30/13_46_58/checkpoint_13300.pth.\n",
      "[2019-05-30 16:02:26,895][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 13400 batch at logs/2019_05_30/13_46_58/checkpoint_13400.pth.\n",
      "[2019-05-30 16:03:26,944][INFO] emmental.logging.checkpointer:102 - Save checkpoint of 13500 batch at logs/2019_05_30/13_46_58/checkpoint_13500.pth.\n",
      "[2019-05-30 16:03:49,079][INFO] emmental.logging.checkpointer:148 - Clear all immediate checkpoints.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-30 16:04:45,573][INFO] emmental.logging.checkpointer:188 - Loading the best model from logs/2019_05_30/13_46_58/best_model_WiC_SuperGLUE_val_accuracy.pth.\n",
      "[2019-05-30 16:04:51,629][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "emmental_learner.learn(mtl_model, dataloaders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WiC_slice_ind_slice_base/SuperGLUE/val/accuracy': 1.0,\n",
       " 'WiC_slice_pred_slice_base/SuperGLUE/val/accuracy': 0.7476489028213166,\n",
       " 'WiC_slice_ind_slice_verb/SuperGLUE/val/accuracy': 0.9968652037617555,\n",
       " 'WiC_slice_pred_slice_verb/SuperGLUE/val/accuracy': 0.7283950617283951,\n",
       " 'WiC/SuperGLUE/val/accuracy': 0.7476489028213166}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WiC_slice_ind_slice_base/SuperGLUE/train/accuracy': 1.0,\n",
       " 'WiC_slice_pred_slice_base/SuperGLUE/train/accuracy': 0.9786293294030951,\n",
       " 'WiC_slice_ind_slice_verb/SuperGLUE/train/accuracy': 1.0,\n",
       " 'WiC_slice_pred_slice_verb/SuperGLUE/train/accuracy': 0.9787395596051632,\n",
       " 'WiC/SuperGLUE/train/accuracy': 0.9784450994841563}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/dfs/scratch0/bradenjh/emmental-tutorials/.venv/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WiC_slice_ind_slice_base/SuperGLUE/val/accuracy': 1.0,\n",
       " 'WiC_slice_pred_slice_base/SuperGLUE/val/accuracy': 0.7476489028213166,\n",
       " 'WiC_slice_ind_slice_verb/SuperGLUE/val/accuracy': 0.9968652037617555,\n",
       " 'WiC_slice_pred_slice_verb/SuperGLUE/val/accuracy': 0.7283950617283951,\n",
       " 'WiC/SuperGLUE/val/accuracy': 0.7476489028213166}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.module_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model1 = EmmentalModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model1.load(\"logs/2019_05_20/17_58_01/best_model_WiC_SuperGLUE_val_accuracy.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# res_dict = mtl_model.predict(dataloaders[\"val\"], return_preds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# res_dict_golds, res_dict_probs, res_dict_preds = res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# res_dict_golds[\"WiC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_dict_probs[\"WiC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_dict_preds[\"WiC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tot = 0\n",
    "# for g, p in zip(res_dict_golds[\"WiC\"], res_dict_preds[\"WiC\"]):\n",
    "#     if g == p:\n",
    "#         tot += 1\n",
    "# print(tot/len(res_dict_golds[\"WiC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset = dataloaders[\"val\"].dataset\n",
    "\n",
    "# for idx in range(len(dataloaders[\"val\"].dataset)):\n",
    "#     if res_dict_golds[\"WiC\"][idx] != res_dict_preds[\"WiC\"][idx]:\n",
    "#         print(\"####\".join([\n",
    "#             str(idx),\n",
    "#             \"True\" if res_dict_golds[\"WiC\"][idx] == 1 else \"False\",\n",
    "#             dataset.X_dict[\"words\"][idx],\n",
    "#             dataset.X_dict[\"poses\"][idx],\n",
    "#             dataset.X_dict[\"sent1\"][idx],\n",
    "#             str(dataset.X_dict[\"sent1_idxs\"][idx].item()),\n",
    "#             dataset.X_dict[\"sent2\"][idx],\n",
    "#             str(dataset.X_dict[\"sent2_idxs\"][idx].item()),\n",
    "#         ])\n",
    "#         )\n",
    "# #     print(dataloaders[\"val\"].dataset.Y_dict[\"labels\"][idx].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
