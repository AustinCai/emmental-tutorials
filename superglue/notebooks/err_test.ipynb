{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import emmental\n",
    "from dataloaders import get_dataloaders\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from slicing.slicing_function import slicing_function\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-06-05 20:07:54,820][INFO] emmental.meta:95 - Setting logging directory to: logs/2019_06_05/20_07_54\n",
      "[2019-06-05 20:07:54,842][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch0/bradenjh/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-06-05 20:07:54,843][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n",
      "[2019-06-05 20:07:54,895][INFO] tokenizer:9 - Loading Tokenizer bert-large-cased\n",
      "[2019-06-05 20:07:55,202][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /afs/cs.stanford.edu/u/paroma/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "[2019-06-05 20:07:55,325][INFO] parsers.rte:20 - Loading data from /dfs/scratch1/senwu/mmtl/emmental-tutorials/superglue/data/RTE/train.jsonl.\n",
      "[2019-06-05 20:07:55,345][INFO] parsers.rte:23 - Sample 0: {'premise': 'No Weapons of Mass Destruction Found in Iraq Yet.', 'hypothesis': 'Weapons of Mass Destruction Found in Iraq.', 'label': 'not_entailment', 'idx': 0}\n",
      "[2019-06-05 20:07:55,346][INFO] parsers.rte:23 - Sample 1: {'premise': 'A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI.', 'hypothesis': 'Pope Benedict XVI is the new leader of the Roman Catholic Church.', 'label': 'entailment', 'idx': 1}\n",
      "[2019-06-05 20:07:57,710][INFO] parsers.rte:93 - Max token len 288\n",
      "[2019-06-05 20:07:57,714][INFO] dataloaders:46 - Loaded train for RTE with 2490 samples.\n",
      "[2019-06-05 20:07:57,715][INFO] parsers.rte:20 - Loading data from /dfs/scratch1/senwu/mmtl/emmental-tutorials/superglue/data/RTE/val.jsonl.\n",
      "[2019-06-05 20:07:57,720][INFO] parsers.rte:23 - Sample 0: {'premise': 'Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.', 'hypothesis': 'Christopher Reeve had an accident.', 'label': 'not_entailment', 'idx': 0}\n",
      "[2019-06-05 20:07:57,721][INFO] parsers.rte:23 - Sample 1: {'premise': 'Yet, we now are discovering that antibiotics are losing their effectiveness against illness. Disease-causing bacteria are mutating faster than we can come up with new antibiotics to fight the new variations.', 'hypothesis': 'Bacteria is winning the war against antibiotics.', 'label': 'entailment', 'idx': 1}\n",
      "[2019-06-05 20:07:58,048][INFO] parsers.rte:93 - Max token len 261\n",
      "[2019-06-05 20:07:58,049][INFO] dataloaders:46 - Loaded val for RTE with 277 samples.\n",
      "[2019-06-05 20:07:58,050][INFO] parsers.rte:20 - Loading data from /dfs/scratch1/senwu/mmtl/emmental-tutorials/superglue/data/RTE/test.jsonl.\n",
      "[2019-06-05 20:07:58,082][INFO] parsers.rte:23 - Sample 0: {'premise': \"Mangla was summoned after Madhumita's sister Nidhi Shukla, who was the first witness in the case.\", 'hypothesis': 'Shukla is related to Mangla.', 'idx': 0}\n",
      "[2019-06-05 20:07:58,083][INFO] parsers.rte:23 - Sample 1: {'premise': \"Authorities in Brazil say that more than 200 people are being held hostage in a prison in the country's remote, Amazonian-jungle state of Rondonia.\", 'hypothesis': 'Authorities in Brazil hold 200 people as hostage.', 'idx': 1}\n",
      "[2019-06-05 20:08:00,635][INFO] parsers.rte:93 - Max token len 256\n",
      "[2019-06-05 20:08:00,638][INFO] dataloaders:46 - Loaded test for RTE with 3000 samples.\n"
     ]
    }
   ],
   "source": [
    "PKL_PATH = \"/dfs/scratch0/paroma/emmental-tutorials/superglue/logs/2019_06_04/17_38_41/best_model_RTE_SuperGLUE_val_accuracy.pth\"\n",
    "SPLIT = \"val\"\n",
    "\n",
    "TASK_NAME = \"RTE\"\n",
    "DATA_DIR = os.environ[\"SUPERGLUEDATA\"]\n",
    "TUTORIALS_ROOT = \"/dfs/scratch0/paroma/emmental-tutorials/\"\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 5,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\n",
    "                \"warmup_percentage\": 0.1,\n",
    "                \"lr_scheduler\": None,\n",
    "            },\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 0.25,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": {\"RTE/SuperGLUE/val/accuracy\":\"max\"},\n",
    "                \"checkpoint_freq\": 1,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "dataloaders = get_dataloaders(\n",
    "            data_dir=DATA_DIR,\n",
    "            task_name=TASK_NAME,\n",
    "            splits=[\"train\", \"val\", \"test\"],\n",
    "            max_sequence_length=256,\n",
    "            tokenizer_name=BERT_MODEL_NAME,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-06-05 20:08:02,021][INFO] pytorch_pretrained_bert.modeling:580 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "[2019-06-05 20:08:02,024][INFO] pytorch_pretrained_bert.modeling:588 - extracting archive file ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpmu4rad7v\n",
      "[2019-06-05 20:08:13,282][INFO] pytorch_pretrained_bert.modeling:598 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[2019-06-05 20:08:19,390][INFO] emmental.task:34 - Created task: RTE\n",
      "[2019-06-05 20:08:19,393][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-06-05 20:08:22,810][INFO] emmental.model:44 - Created emmental model SuperGLUE that contains task {'RTE'}.\n",
      "[2019-06-05 20:08:22,812][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-06-05 20:08:24,914][INFO] emmental.model:428 - [SuperGLUE] Model loaded from /dfs/scratch0/paroma/emmental-tutorials/superglue/logs/2019_06_04/17_38_41/best_model_RTE_SuperGLUE_val_accuracy.pth\n",
      "[2019-06-05 20:08:24,915][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "# Load model and sanity check quality\n",
    "# model = get_and_load_model()\n",
    "import models\n",
    "tasks = [models.model[TASK_NAME](BERT_MODEL_NAME)]\n",
    "model = EmmentalModel(name=f\"SuperGLUE\", tasks=tasks)\n",
    "model.load(PKL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RTE/SuperGLUE/train/accuracy': 0.9891566265060241,\n",
       " 'RTE/SuperGLUE/val/accuracy': 0.7689530685920578,\n",
       " 'RTE/SuperGLUE/test/accuracy': 0.5793333333333334}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(dataloaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TIME TO SLICE!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@slicing_function()\n",
    "def slice_base(example):\n",
    "    return 1\n",
    "\n",
    "@slicing_function(fields=[\"sentence1\", \"sentence2\"])\n",
    "def slice_nasa(example):\n",
    "    return 'NASA' in example.sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import slicing\n",
    "slices = [\n",
    "    slice_base,\n",
    "    slice_nasa,\n",
    "]\n",
    "\n",
    "slice_func_dict = {slice.__name__: slice for slice in slices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'slice_base': <function __main__.slice_base(example)>,\n",
       " 'slice_nasa': <function __main__.slice_nasa(example)>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_func_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-06-05 20:55:47,514][INFO] slicing.slicing_function:38 - Total 2490 / 2490 examples are in slice slice_base\n",
      "[2019-06-05 20:55:47,522][INFO] slicing.slicing_function:38 - Total 5 / 2490 examples are in slice slice_nasa\n",
      "[2019-06-05 20:55:52,080][INFO] slicing.slicing_function:38 - Total 277 / 277 examples are in slice slice_base\n",
      "[2019-06-05 20:55:52,081][INFO] slicing.slicing_function:38 - Total 2 / 277 examples are in slice slice_nasa\n",
      "[2019-06-05 20:56:29,753][INFO] slicing.slicing_function:38 - Total 3000 / 3000 examples are in slice slice_base\n",
      "[2019-06-05 20:56:29,768][INFO] slicing.slicing_function:38 - Total 20 / 3000 examples are in slice slice_nasa\n"
     ]
    }
   ],
   "source": [
    "return_uids=False\n",
    "\n",
    "metric_score_dict = dict()\n",
    "for dataloader in dataloaders:\n",
    "    preds = model.predict(dataloader, return_preds=True, return_uids=False)\n",
    "    for task_name in preds[\"golds\"].keys():\n",
    "        metric_score = model.scorers[task_name].score(\n",
    "            preds[\"golds\"][task_name],\n",
    "            preds[\"probs\"][task_name],\n",
    "            preds[\"preds\"][task_name],\n",
    "            preds[\"uids\"][task_name] if return_uids else None,\n",
    "        )\n",
    "        \n",
    "        for metric_name, metric_value in metric_score.items():\n",
    "            identifier = \"/\".join(\n",
    "                [task_name, dataloader.data_name, dataloader.split, metric_name]\n",
    "            )\n",
    "            metric_score_dict[identifier] = metric_value\n",
    "        \n",
    "            for slice_id,slice_func in slice_func_dict.items():\n",
    "                slice_idx = slice_func(dataloader.dataset)[0].numpy().astype(bool)\n",
    "                slice_score = model.scorers[task_name].score(preds[\"golds\"][task_name][slice_idx], preds[\"probs\"][task_name][slice_idx], preds[\"preds\"][task_name][slice_idx])\n",
    "\n",
    "                for metric_name, metric_value in slice_score.items():\n",
    "                    identifier = \"/\".join(\n",
    "                        [task_name, dataloader.data_name, dataloader.split+'+'+slice_id, metric_name]\n",
    "                    )\n",
    "                    metric_score_dict[identifier] = metric_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
