{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from parse_WiC import get_WiC_dataloaders\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 4,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\n",
    "                \"warmup_percentage\": 0.1,\n",
    "                \"lr_scheduler\": None,\n",
    "            },\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 100,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": {\"WiC/SuperGLUE/val/accuracy\":\"max\"},\n",
    "                \"checkpoint_freq\": 1,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TASK_NAME = \"WiC\"\n",
    "DATA_DIR = \"/dfs/scratch0/bradenjh/superglue\" #os.environ[\"SUPERGLUEDATA\"]\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataloaders = get_WiC_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\", \"test\"],\n",
    "    max_sequence_length=128,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(task_name, immediate_ouput_dict, Y, active):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(task_name, immediate_ouput_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(golds, probs, preds):\n",
    "    return {\"macro_f1\": f1_score(golds, preds, average=\"macro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, feature, idx1, idx2):\n",
    "        last_layer = feature[-1]\n",
    "        emb = last_layer[:,0,:]\n",
    "        idx1 = idx1.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        idx2 = idx2.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        word1_emb = last_layer.gather(dim=1, index=idx1).squeeze(dim=1)\n",
    "        word2_emb = last_layer.gather(dim=1, index=idx2).squeeze(dim=1)\n",
    "        input = torch.cat([emb, word1_emb, word2_emb], dim=-1)\n",
    "        return self.linear.forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")\n",
    "\n",
    "emmental_task = EmmentalTask(\n",
    "    name=TASK_NAME,\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "            f\"{TASK_NAME}_pred_head\": LinearModule(3 * BERT_OUTPUT_DIM, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": \"input\",\n",
    "            \"module\": \"bert_module\",\n",
    "            \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "        },\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [(\"input\", 0), (\"_input_\", \"sent1_idxs\"), (\"_input_\", \"sent2_idxs\")],\n",
    "        },\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, TASK_NAME),\n",
    "    output_func=partial(output, TASK_NAME),\n",
    "    scorer=Scorer(\n",
    "        metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=[emmental_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# emmental_learner.learn(mtl_model, dataloaders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.score(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PKL_PATH = \"/dfs/scratch0/bradenjh/emmental-tutorials/superglue/models/WiC_verb_trigram_v2.pth\"\n",
    "# PKL_PATH = \"/dfs/scratch0/bradenjh/emmental-tutorials/superglue/logs/2019_05_29/13_59_55/best_model_WiC_SuperGLUE_val_accuracy.pth\"\n",
    "PKL_PATH = \"/dfs/scratch0/bradenjh/emmental-tutorials/superglue/logs/2019_06_04/11_01_21/best_model_WiC_SuperGLUE_val_accuracy.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.save(PKL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=[emmental_task])\n",
    "new_model.load(PKL_PATH)\n",
    "new_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from task_config import (\n",
    "    SuperGLUE_LABEL_MAPPING, \n",
    "    SuperGLUE_TASK_METRIC_MAPPING, \n",
    "    SuperGLUE_TASK_SPLIT_MAPPING\n",
    ")\n",
    "\n",
    "SPLIT = \"val\"\n",
    "\n",
    "def make_analysis_df(model):\n",
    "    # Get predictions\n",
    "    gold_dict, prob_dict, pred_dict = model.predict(dataloaders[SPLIT], return_preds=True)\n",
    "    probs = prob_dict[\"WiC\"][:,0]\n",
    "    preds = pred_dict[\"WiC\"]\n",
    "\n",
    "    # Load raw data\n",
    "    jsonl_path = os.path.join(\n",
    "        DATA_DIR, TASK_NAME, SuperGLUE_TASK_SPLIT_MAPPING[TASK_NAME][SPLIT]\n",
    "    )\n",
    "\n",
    "    # Add new columns\n",
    "    rows = [json.loads(row) for row in open(jsonl_path, encoding=\"utf-8\")]\n",
    "    for i, row in enumerate(rows):\n",
    "        row[\"prob\"] = probs[i]\n",
    "        row[\"pred\"] = True if preds[i] == 1 else False\n",
    "        row[\"correct\"] = \"Y\" if row[\"pred\"] == row[\"label\"] else \"N\"\n",
    "\n",
    "    # Make tsv\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df[['idx', 'label', 'pred', 'prob', 'correct', 'word', 'pos', \n",
    "             'sentence1_idx', 'sentence2_idx',\n",
    "             'sentence1', 'sentence2']]\n",
    "    return df\n",
    "\n",
    "df = make_analysis_df(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTORIALS_ROOT = \"/dfs/scratch0/bradenjh/emmental-tutorials/\"\n",
    "\n",
    "# out_path = os.path.join(TUTORIALS_ROOT, \"superglue\", \"analysis\", f\"WiC_{SPLIT}_analysis_v0.csv\")\n",
    "# df.to_csv(out_path)\n",
    "# print(f\"Wrote error analysis to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import stopwords as nltk_stopwords\n",
    "# stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "def get_ngrams(tokens, window=1):\n",
    "    num_ngrams = len(tokens) - window + 1\n",
    "    for i in range(num_ngrams):\n",
    "        yield tokens[i:i+window]\n",
    "        \n",
    "for index, row in df.iterrows():\n",
    "    target = row[\"word\"]\n",
    "    labels.append(1 if row[\"label\"] == True else 2)\n",
    "    sent1_target = row[\"sentence1\"].split()[int(row[\"sentence1_idx\"])]\n",
    "    sent2_target = row[\"sentence2\"].split()[int(row[\"sentence2_idx\"])]\n",
    "    if sent1_target.lower() != sent2_target.lower():\n",
    "        print(index, sent1_target.lower(), sent2_target.lower())\n",
    "#     print(row)\n",
    "#     print(word, )\n",
    "#     for sent in [\"sentence1\", \"sentence2\"]:\n",
    "#         tokens = row[sent].split()\n",
    "#         for i, tok in enumerate(tokens):\n",
    "#             if target in tok:\n",
    "#                 idx = i\n",
    "#                 break\n",
    "#         trigrams.append([' '.join(ngram) \n",
    "#                          for ngram in get_ngrams(tokens[idx-2:idx+2], window=3) \n",
    "#                          if len(ngram) == 3])\n",
    "#     if (set(trigrams[0]).intersection(set(trigrams[1]))):\n",
    "#         preds.append(1)\n",
    "#         print(trigrams)\n",
    "#         print(f\"{target}: {row['sentence1']}.....{row['sentence2']}\")\n",
    "#         print()        \n",
    "#     else:\n",
    "#         preds.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.metrics import *\n",
    "\n",
    "print(accuracy_score(labels, preds, ignore_in_pred=[0]))\n",
    "print(coverage_score(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
