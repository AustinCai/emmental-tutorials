{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing Formula:\n",
    "1. look at errors for ideas\n",
    "2. write a slice function\n",
    "3. check slice size (large enough to matter?)\n",
    "4. check performance on that slice with trained model (are we underperforming?)\n",
    "5. train a model on just that slice (can we do better on it?)\n",
    "6. train a full model including that slice (does that gain persist?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import emmental\n",
    "from dataloaders import get_dataloaders\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from slicing.slicing_function import slicing_function\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-06-10 14:12:38,408][INFO] emmental.meta:99 - Logging was already initialized to use logs/2019_06_10/14_10_22.  To configure logging manually, call emmental.init_logging before initialiting Meta.\n",
      "[2019-06-10 14:12:38,419][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch1/bradenjh/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-06-10 14:12:38,419][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n",
      "[2019-06-10 14:12:38,420][INFO] tokenizer:9 - Loading Tokenizer bert-large-cased\n",
      "[2019-06-10 14:12:38,683][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /dfs/scratch1/bradenjh/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "[2019-06-10 14:12:38,717][INFO] parsers.wic:20 - Loading data from /dfs/scratch1/senwu/mmtl/emmental-tutorials/superglue/data/WiC/train.jsonl.\n",
      "[2019-06-10 14:12:38,751][INFO] parsers.wic:23 - Sample 0: {'label': False, 'word': 'carry', 'pos': 'V', 'sentence1': 'You must carry your camping gear .', 'sentence2': 'Sound carries well over water .', 'sentence1_idx': '2', 'sentence2_idx': '1', 'idx': 0}\n",
      "[2019-06-10 14:12:38,752][INFO] parsers.wic:23 - Sample 1: {'label': False, 'word': 'go', 'pos': 'V', 'sentence1': 'Messages must go through diplomatic channels .', 'sentence2': 'Do you think the sofa will go through the door ?', 'sentence1_idx': '2', 'sentence2_idx': '6', 'idx': 1}\n",
      "[2019-06-10 14:12:40,634][INFO] parsers.wic:136 - Max token len 68\n",
      "[2019-06-10 14:12:40,638][INFO] dataloaders:46 - Loaded train for WiC with 5428 samples.\n",
      "[2019-06-10 14:12:40,639][INFO] parsers.wic:20 - Loading data from /dfs/scratch1/senwu/mmtl/emmental-tutorials/superglue/data/WiC/val.jsonl.\n",
      "[2019-06-10 14:12:40,643][INFO] parsers.wic:23 - Sample 0: {'label': False, 'word': 'board', 'pos': 'N', 'sentence1': 'Room and board .', 'sentence2': 'He nailed boards across the windows .', 'sentence1_idx': '2', 'sentence2_idx': '2', 'idx': 0}\n",
      "[2019-06-10 14:12:40,644][INFO] parsers.wic:23 - Sample 1: {'label': False, 'word': 'circulate', 'pos': 'V', 'sentence1': 'Circulate a rumor .', 'sentence2': 'This letter is being circulated among the faculty .', 'sentence1_idx': '0', 'sentence2_idx': '4', 'idx': 1}\n",
      "[2019-06-10 14:12:40,875][INFO] parsers.wic:136 - Max token len 57\n",
      "[2019-06-10 14:12:40,876][INFO] dataloaders:46 - Loaded val for WiC with 638 samples.\n",
      "[2019-06-10 14:12:40,877][INFO] parsers.wic:20 - Loading data from /dfs/scratch1/senwu/mmtl/emmental-tutorials/superglue/data/WiC/test.jsonl.\n",
      "[2019-06-10 14:12:40,885][INFO] parsers.wic:23 - Sample 0: {'word': 'defeat', 'pos': 'N', 'sentence1': 'It was a narrow defeat .', 'sentence2': \"The army 's only defeat .\", 'sentence1_idx': '4', 'sentence2_idx': '4', 'idx': 0}\n",
      "[2019-06-10 14:12:40,886][INFO] parsers.wic:23 - Sample 1: {'word': 'groom', 'pos': 'V', 'sentence1': 'Groom the dogs .', 'sentence2': 'Sheila groomed the horse .', 'sentence1_idx': '0', 'sentence2_idx': '1', 'idx': 1}\n",
      "[2019-06-10 14:12:41,390][INFO] parsers.wic:136 - Max token len 60\n",
      "[2019-06-10 14:12:41,391][INFO] dataloaders:46 - Loaded test for WiC with 1400 samples.\n"
     ]
    }
   ],
   "source": [
    "PKL_PATH = \"/dfs/scratch1/bradenjh/emmental-tutorials/superglue/logs/2019_06_04/14_22_40/best_model_WiC_SuperGLUE_val_accuracy.pth\"\n",
    "SPLIT = \"val\"\n",
    "\n",
    "TASK_NAME = \"WiC\"\n",
    "DATA_DIR = os.environ[\"SUPERGLUEDATA\"]\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 5,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\n",
    "                \"warmup_percentage\": 0.1,\n",
    "                \"lr_scheduler\": None,\n",
    "            },\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 0.25,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": {\"RTE/SuperGLUE/val/accuracy\":\"max\"},\n",
    "                \"checkpoint_freq\": 1,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "dataloaders = get_dataloaders(\n",
    "            data_dir=DATA_DIR,\n",
    "            task_name=TASK_NAME,\n",
    "            splits=[\"train\", \"val\", \"test\"],\n",
    "            max_sequence_length=256,\n",
    "            tokenizer_name=BERT_MODEL_NAME,\n",
    "            batch_size=BATCH_SIZE,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do offline: load saved model, make csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write Slice Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slicing.slicing_function import slicing_function\n",
    "\n",
    "@slicing_function(fields=[\"pos\", \"sentence1\", \"sentence2\", \"sentence1_idx\", \"sentence2_idx\"])\n",
    "def sf(example):\n",
    "    \"\"\"Is the target word a noun with different forms between sentences?\"\"\"\n",
    "    form1 = example.sentence1.split()[example.sentence1_idx]\n",
    "    form2 = example.sentence2.split()[example.sentence2_idx]\n",
    "    return (form1 != form2) and example.pos == \"V\"\n",
    "\n",
    "slicing_functions = [\n",
    "    sf,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Apply SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-06-10 14:40:47,747][INFO] slicing.slicing_function:43 - Total 1830 / 5428 examples are in slice sf\n"
     ]
    }
   ],
   "source": [
    "inds, preds = sf(dataloaders[0].dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is slice large enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice labels 1830/5428 (0.3371407516580693) examples\n",
      "Slice polarity: 794/1830 (0.43387978142076505) positive class\n"
     ]
    }
   ],
   "source": [
    "count = (inds == 1).sum()\n",
    "total = len(inds)\n",
    "print(f\"Slice labels {count}/{total} ({float(count)/total}) examples\")\n",
    "\n",
    "slice_preds = preds[inds == 1].numpy()\n",
    "print(f\"Slice polarity: {sum(slice_preds == 1)}/{len(slice_preds)} ({sum(slice_preds == 1)/len(slice_preds)}) positive class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Static check slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-06-10 14:20:30,814][INFO] pytorch_pretrained_bert.modeling:580 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "[2019-06-10 14:20:30,816][INFO] pytorch_pretrained_bert.modeling:588 - extracting archive file ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpzxj_w4mp\n",
      "[2019-06-10 14:20:42,799][INFO] pytorch_pretrained_bert.modeling:598 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[2019-06-10 14:20:47,893][INFO] emmental.task:34 - Created task: WiC\n",
      "[2019-06-10 14:20:47,895][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-06-10 14:20:48,115][INFO] emmental.model:44 - Created emmental model SuperGLUE that contains task {'WiC'}.\n",
      "[2019-06-10 14:20:48,116][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n",
      "[2019-06-10 14:20:59,517][INFO] emmental.model:432 - [SuperGLUE] Model loaded from /dfs/scratch1/bradenjh/emmental-tutorials/superglue/logs/2019_06_04/14_22_40/best_model_WiC_SuperGLUE_val_accuracy.pth\n",
      "[2019-06-10 14:20:59,519][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "tasks = [models.model[TASK_NAME](BERT_MODEL_NAME)]\n",
    "model = EmmentalModel(name=f\"SuperGLUE\", tasks=tasks)\n",
    "model.load(PKL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score base and slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-06-10 14:20:59,889][INFO] root:201 - Evaluating on task WiC, val split\n",
      "[2019-06-10 14:21:06,177][INFO] root:208 - Evaluating slice slice_base\n",
      "[2019-06-10 14:21:06,188][INFO] slicing.slicing_function:43 - Total 638 / 638 examples are in slice slice_base\n",
      "[2019-06-10 14:21:06,188][INFO] root:208 - Evaluating slice slice_verb\n",
      "[2019-06-10 14:21:06,191][INFO] slicing.slicing_function:43 - Total 243 / 638 examples are in slice slice_verb\n",
      "[2019-06-10 14:21:06,192][INFO] root:208 - Evaluating slice slice_noun\n",
      "[2019-06-10 14:21:06,196][INFO] slicing.slicing_function:43 - Total 395 / 638 examples are in slice slice_noun\n",
      "[2019-06-10 14:21:06,197][INFO] root:208 - Evaluating slice slice_trigram\n",
      "[2019-06-10 14:21:06,203][INFO] slicing.slicing_function:43 - Total 16 / 638 examples are in slice slice_trigram\n",
      "[2019-06-10 14:21:06,203][INFO] root:208 - Evaluating slice slice_mismatch_verb\n",
      "[2019-06-10 14:21:06,208][INFO] slicing.slicing_function:43 - Total 192 / 638 examples are in slice slice_mismatch_verb\n",
      "[2019-06-10 14:21:06,208][INFO] root:208 - Evaluating slice slice_mismatch_noun\n",
      "[2019-06-10 14:21:06,212][INFO] slicing.slicing_function:43 - Total 111 / 638 examples are in slice slice_mismatch_noun\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7445141065830722,\n",
       " 'WiC:slice_base/SuperGLUE/val/accuracy': 0.7445141065830722,\n",
       " 'WiC:slice_verb/SuperGLUE/val/accuracy': 0.7325102880658436,\n",
       " 'WiC:slice_noun/SuperGLUE/val/accuracy': 0.7518987341772152,\n",
       " 'WiC:slice_trigram/SuperGLUE/val/accuracy': 0.75,\n",
       " 'WiC:slice_mismatch_verb/SuperGLUE/val/accuracy': 0.734375,\n",
       " 'WiC:slice_mismatch_noun/SuperGLUE/val/accuracy': 0.7927927927927928}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from slicing import score_slices, slice_func_dict\n",
    "\n",
    "# slice_func_dict = {sf.__name__: sf for sf in slicing_functions}\n",
    "slice_func_dict = slice_func_dict[TASK_NAME]\n",
    "\n",
    "slice_scores = score_slices(model, [dataloaders[1]], [TASK_NAME], slice_func_dict)\n",
    "slice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
