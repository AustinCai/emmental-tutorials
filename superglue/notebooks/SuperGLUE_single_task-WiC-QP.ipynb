{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from parse_WiC_slice import get_WiC_dataloaders\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 10,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\"warmup_percentage\": 0.1, \"lr_scheduler\": None},\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"batch\",\n",
    "            \"evaluation_freq\": 100,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\"checkpoint_metric\": {\"WiC/SuperGLUE/val/accuracy\":\"max\"}},\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "TASK_NAME = \"WiC\"\n",
    "DATA_DIR = os.environ[\"SUPERGLUEDATA\"]\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_OUTPUT_DIM, TASK_CARDINALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slice_WiC import slice_func_dict\n",
    "\n",
    "slice_func_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataloaders = get_WiC_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\", \"test\"],\n",
    "    max_sequence_length=256,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    slice_func_dict=slice_func_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders[\"train\"].task_to_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dataloaders[\"train\"].dataset.Y_dict.items():\n",
    "    print(key, value.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(module_name, immediate_ouput_dict, Y, active):\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(module_name, immediate_ouput_dict):\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureConcateModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, feature, idx1, idx2):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        last_layer = feature[-1]\n",
    "        emb = last_layer[:,0,:]\n",
    "        idx1 = idx1.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        idx2 = idx2.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "        word1_emb = last_layer.gather(dim=1, index=idx1).squeeze(dim=1)\n",
    "        word2_emb = last_layer.gather(dim=1, index=idx2).squeeze(dim=1)\n",
    "        input = torch.cat([emb, word1_emb, word2_emb], dim=-1)\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        return self.linear.forward(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = BERT_OUTPUT_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_classification_module = nn.Linear(H, TASK_CARDINALITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_module = BertModule(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"ind\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": SliceModule(\n",
    "                    3 * BERT_OUTPUT_DIM, 2\n",
    "                ),\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"feature\",\n",
    "                \"module\": f\"feature\",\n",
    "                \"inputs\": [\n",
    "                    (\"input\", 0),\n",
    "                    (\"_input_\", \"sent1_idxs\"),\n",
    "                    (\"_input_\", \"sent2_idxs\"),\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(metrics=[\"accuracy\"]),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"pred\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_feat_{slice_name}\": nn.Linear(3 * BERT_OUTPUT_DIM, H),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": shared_classification_module,\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"feature\",\n",
    "                \"module\": f\"feature\",\n",
    "                \"inputs\": [\n",
    "                    (\"input\", 0),\n",
    "                    (\"_input_\", \"sent1_idxs\"),\n",
    "                    (\"_input_\", \"sent2_idxs\"),\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(f\"{TASK_NAME}_slice_feat_{slice_name}\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, immediate_ouput_dict):\n",
    "        slice_ind_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_ind_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "        slice_pred_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_pred_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        Q = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_ind_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_ind_name in slice_ind_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        P = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_pred_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_pred_name in slice_pred_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        slice_feat_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_feat_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        slice_reps = torch.cat(\n",
    "            [\n",
    "                immediate_ouput_dict[slice_feat_name][0].unsqueeze(1)\n",
    "                for slice_feat_name in slice_feat_names\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        A = F.softmax(Q * P, dim=1).unsqueeze(-1).expand([-1, -1, slice_reps.size(-1)])\n",
    "\n",
    "        reweighted_rep = torch.sum(A * slice_reps, 1)\n",
    "\n",
    "        return self.linear.forward(reweighted_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_task = EmmentalTask(\n",
    "    name=f\"{TASK_NAME}\",\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": bert_module,\n",
    "            f\"{TASK_NAME}_pred_head\": MasterModule(H, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [],\n",
    "        }\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, f\"{TASK_NAME}_pred_head\"),\n",
    "    output_func=partial(output, f\"{TASK_NAME}_pred_head\"),\n",
    "    scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    ")\n",
    "tasks.append(master_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for X, Y in dataloaders[\"train\"]:\n",
    "#     import pdb; pdb.set_trace()\n",
    "# # #     print(X, Y)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# emmental_learner.learn(mtl_model, dataloaders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.score(dataloaders[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKL_PATH = \"/dfs/scratch0/bradenjh/emmental-tutorials/superglue/models/WiC_verb_trigram_v2.pth\"\n",
    "new_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=tasks)\n",
    "new_model.load(PKL_PATH)\n",
    "new_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
