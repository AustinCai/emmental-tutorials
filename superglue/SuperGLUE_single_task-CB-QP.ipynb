{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from torch import nn\n",
    "\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from parse_CB_slice import get_CB_dataloaders\n",
    "from task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:00,942][INFO] emmental.meta:95 - Setting logging directory to: logs/2019_05_22/18_34_00\n",
      "[2019-05-22 18:34:00,960][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch1/senwu/mmtl/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-05-22 18:34:00,961][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\n",
    "    \"logs\",\n",
    "    config={\n",
    "        \"meta_config\": {\"seed\": 111},\n",
    "        \"model_config\": {\"device\": 1, \"dataparallel\": False},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 20,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 0.00001},\n",
    "            \"min_lr\": 0,\n",
    "            \"lr_scheduler_config\": {\"warmup_percentage\": 0.1, \"lr_scheduler\": \"linear\"},\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"epoch\",\n",
    "            \"evaluation_freq\": 1,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": {\"CB/SuperGLUE/val/accuacy_macro_f1\": \"max\"}\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta_config': {'seed': 111, 'verbose': True, 'log_path': None},\n",
       " 'model_config': {'model_path': None, 'device': 1, 'dataparallel': False},\n",
       " 'learner_config': {'fp16': False,\n",
       "  'n_epochs': 20,\n",
       "  'train_split': 'train',\n",
       "  'valid_split': 'val',\n",
       "  'test_split': 'test',\n",
       "  'ignore_index': -100,\n",
       "  'optimizer_config': {'optimizer': 'adam',\n",
       "   'lr': 1e-05,\n",
       "   'l2': 0.0,\n",
       "   'grad_clip': 1.0,\n",
       "   'sgd_config': {'momentum': 0.9},\n",
       "   'adam_config': {'betas': (0.9, 0.999)}},\n",
       "  'lr_scheduler_config': {'lr_scheduler': 'linear',\n",
       "   'warmup_steps': None,\n",
       "   'warmup_unit': 'batch',\n",
       "   'warmup_percentage': 0.1,\n",
       "   'min_lr': 0.0,\n",
       "   'linear_config': {'min_lr': 0.0},\n",
       "   'exponential_config': {'gamma': 0.9},\n",
       "   'plateau_config': {'factor': 0.5, 'patience': 10, 'threshold': 0.0001}},\n",
       "  'task_scheduler': 'round_robin',\n",
       "  'global_evaluation_metric_dict': None,\n",
       "  'min_lr': 0},\n",
       " 'logging_config': {'counter_unit': 'epoch',\n",
       "  'evaluation_freq': 1,\n",
       "  'writer_config': {'writer': 'tensorboard', 'verbose': True},\n",
       "  'checkpointing': True,\n",
       "  'checkpointer_config': {'checkpoint_path': None,\n",
       "   'checkpoint_freq': 1,\n",
       "   'checkpoint_metric': {'CB/SuperGLUE/val/accuacy_macro_f1': 'max'},\n",
       "   'checkpoint_task_metrics': None,\n",
       "   'checkpoint_runway': 0,\n",
       "   'checkpoint_clear': True}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Meta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"CB\"\n",
    "DATA_DIR = \"data\"\n",
    "BERT_MODEL_NAME = \"bert-large-cased\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BERT_OUTPUT_DIM, TASK_CARDINALITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev dataset from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_base(dataset):\n",
    "    slice_name = \"slice_base\"\n",
    "    return torch.from_numpy(np.array([1] * len(dataset))), dataset.Y_dict[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_base_1(dataset):\n",
    "    slice_name = \"slice_base_1\"\n",
    "    return torch.from_numpy(np.array([1] * len(dataset))), dataset.Y_dict[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['slice_base', 'slice_base_1'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_func_dict = {\n",
    "    \"slice_base\": slice_base,\n",
    "    \"slice_base_1\": slice_base_1,\n",
    "}\n",
    "slice_func_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:01,276][INFO] tokenizer:8 - Loading Tokenizer bert-large-cased\n",
      "[2019-05-22 18:34:01,568][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/cee054f6aafe5e2cf816d2228704e326446785f940f5451a5b26033516a4ac3d.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/CB/train.jsonl\n",
      "{'premise': 'It was a complex language. Not written down but handed down. One might say it was peeled down.', 'hypothesis': 'the language was peeled down', 'label': 'entailment', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:02,125][INFO] parse_CB_slice:133 - Loaded train for CB.\n",
      "[2019-05-22 18:34:02,256][INFO] parse_CB_slice:133 - Loaded val for CB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/CB/val.jsonl\n",
      "{'premise': \"Valence the void-brain, Valence the virtuous valet. Why couldn't the figger choose his own portion of titanic anatomy to shaft? Did he think he was helping?\", 'hypothesis': 'Valence was helping', 'label': 'contradiction', 'idx': 0}\n",
      "data/CB/test.jsonl\n",
      "{'premise': 'Polly had to think quickly. They were still close enough to shore for him to return her to the police if she admitted she was not an experienced ocean sailor.', 'hypothesis': 'Polly was not an experienced ocean sailor', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:02,808][INFO] parse_CB_slice:133 - Loaded test for CB.\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_CB_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\", \"test\"],\n",
    "    max_sequence_length=256,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    slice_func_dict=slice_func_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "         1, 1, 2, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "         3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "         2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "         1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "         2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
       "         2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1,\n",
       "         3, 1, 3, 3, 1, 3, 3, 1, 3, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 1, 2, 2, 2, 2, 1, 1, 1, 1]),\n",
       " 'CB_slice_ind_slice_base': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'CB_slice_pred_slice_base': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "         1, 1, 2, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "         3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "         2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "         1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "         2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
       "         2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1,\n",
       "         3, 1, 3, 3, 1, 3, 3, 1, 3, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 1, 2, 2, 2, 2, 1, 1, 1, 1]),\n",
       " 'CB_slice_ind_slice_base_1': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'CB_slice_pred_slice_base_1': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "         1, 1, 2, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "         3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "         2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "         1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "         2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2,\n",
       "         2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1,\n",
       "         3, 1, 3, 3, 1, 3, 3, 1, 3, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 1, 2, 2, 2, 2, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders[\"train\"].dataset.Y_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(module_name, immediate_ouput_dict, Y, active):\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(module_name, immediate_ouput_dict):\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1(golds, probs, preds):\n",
    "    return {\"macro_f1\": f1_score(golds, preds, average=\"macro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emmental.metrics.accuracy import accuracy_scorer\n",
    "\n",
    "def accuacy_macro_f1(golds, probs, preds):\n",
    "    metric_dict = macro_f1(golds, probs, preds)\n",
    "    metric_dict.update(accuracy_scorer(golds, probs, preds))\n",
    "    metric_dict[\"accuacy_macro_f1\"] = (metric_dict[\"accuracy\"] + metric_dict[\"macro_f1\"]) / 2\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:03,360][INFO] pytorch_pretrained_bert.modeling:580 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz from cache at ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233\n",
      "[2019-05-22 18:34:03,364][INFO] pytorch_pretrained_bert.modeling:588 - extracting archive file ./cache/7fb0534b83c42daee7d3ddb0ebaa81387925b71665d6ea195c5447f1077454cd.eea60d9ebb03c75bb36302aa9d241d3b7a04bba39c360cf035e8bf8140816233 to temp dir /tmp/tmpmcypep1t\n",
      "[2019-05-22 18:34:20,819][INFO] pytorch_pretrained_bert.modeling:598 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "H = BERT_OUTPUT_DIM\n",
    "shared_classification_module = nn.Linear(H, TASK_CARDINALITY)\n",
    "bert_module = BertModule(BERT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureConcateModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, feature, idx1=None, idx2=None):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        last_layer = feature[-1]\n",
    "        emb = last_layer[:,0,:]\n",
    "        \n",
    "        if idx1 and idx2:\n",
    "            idx1 = idx1.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "            idx2 = idx2.unsqueeze(-1).unsqueeze(-1).expand([-1, -1, last_layer.size(-1)])\n",
    "            word1_emb = last_layer.gather(dim=1, index=idx1).squeeze(dim=1)\n",
    "            word2_emb = last_layer.gather(dim=1, index=idx2).squeeze(dim=1)\n",
    "            input = torch.cat([emb, word1_emb, word2_emb], dim=-1)\n",
    "        else:\n",
    "            input = emb\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:52,314][INFO] emmental.task:34 - Created task: CB_slice_ind_slice_base\n",
      "[2019-05-22 18:34:52,316][INFO] emmental.task:34 - Created task: CB_slice_ind_slice_base_1\n"
     ]
    }
   ],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"ind\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": nn.Linear(\n",
    "                    CAT * BERT_OUTPUT_DIM, 2\n",
    "                ),\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\"name\": f\"feature\", \"module\": f\"feature\", \"inputs\": [(\"input\", 0)]},\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(metrics=[\"accuracy\"]),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:52,373][INFO] emmental.task:34 - Created task: CB_slice_pred_slice_base\n",
      "[2019-05-22 18:34:52,388][INFO] emmental.task:34 - Created task: CB_slice_pred_slice_base_1\n"
     ]
    }
   ],
   "source": [
    "# Add ind task\n",
    "\n",
    "type = \"pred\"\n",
    "\n",
    "for slice_name in slice_func_dict.keys():\n",
    "    task = EmmentalTask(\n",
    "        name=f\"{TASK_NAME}_slice_{type}_{slice_name}\",\n",
    "        module_pool=nn.ModuleDict(\n",
    "            {\n",
    "#                 \"bert_module\": bert_module,\n",
    "                \"feature\": FeatureConcateModule(),\n",
    "                f\"{TASK_NAME}_slice_feat_{slice_name}\": nn.Linear(\n",
    "                    CAT * BERT_OUTPUT_DIM, H\n",
    "                ),\n",
    "                f\"{TASK_NAME}_slice_{type}_{slice_name}_head\": shared_classification_module,\n",
    "            }\n",
    "        ),\n",
    "        task_flow=[\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"module\": \"bert_module\",\n",
    "                \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"feature\",\n",
    "                \"module\": f\"feature\",\n",
    "                \"inputs\": [\n",
    "                    (\"input\", 0),\n",
    "                    #                     (\"_input_\", \"sent1_idxs\"),\n",
    "                    #                     (\"_input_\", \"sent2_idxs\"),\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_feat_{slice_name}\",\n",
    "                \"inputs\": [(\"feature\", 0)],\n",
    "            },\n",
    "            {\n",
    "                \"name\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"module\": f\"{TASK_NAME}_slice_{type}_{slice_name}_head\",\n",
    "                \"inputs\": [(f\"{TASK_NAME}_slice_feat_{slice_name}\", 0)],\n",
    "            },\n",
    "        ],\n",
    "        loss_func=partial(ce_loss, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        output_func=partial(output, f\"{TASK_NAME}_slice_{type}_{slice_name}_head\"),\n",
    "        scorer=Scorer(customize_metric_funcs={\"accuacy_macro_f1\": accuacy_macro_f1}),\n",
    "    )\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterModule(nn.Module):\n",
    "    def __init__(self, feature_dim, class_cardinality):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(feature_dim, class_cardinality)\n",
    "\n",
    "    def forward(self, immediate_ouput_dict):\n",
    "        slice_ind_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_ind_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "        slice_pred_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_pred_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        Q = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_ind_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_ind_name in slice_ind_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "        P = torch.cat(\n",
    "            [\n",
    "                F.softmax(immediate_ouput_dict[slice_pred_name][0])[:, 0].unsqueeze(1)\n",
    "                for slice_pred_name in slice_pred_names\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        slice_feat_names = sorted(\n",
    "            [\n",
    "                flow_name\n",
    "                for flow_name in immediate_ouput_dict.keys()\n",
    "                if \"_slice_feat_\" in flow_name\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        slice_reps = torch.cat(\n",
    "            [\n",
    "                immediate_ouput_dict[slice_feat_name][0].unsqueeze(1)\n",
    "                for slice_feat_name in slice_feat_names\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        A = F.softmax(Q * P, dim=1).unsqueeze(-1).expand([-1, -1, slice_reps.size(-1)])\n",
    "\n",
    "        reweighted_rep = torch.sum(A * slice_reps, 1)\n",
    "\n",
    "        return self.linear.forward(reweighted_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:52,471][INFO] emmental.task:34 - Created task: CB\n"
     ]
    }
   ],
   "source": [
    "master_task = EmmentalTask(\n",
    "    name=f\"{TASK_NAME}\",\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": bert_module,\n",
    "            f\"{TASK_NAME}_pred_head\": MasterModule(H, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [],\n",
    "        }\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, f\"{TASK_NAME}_pred_head\"),\n",
    "    output_func=partial(output, f\"{TASK_NAME}_pred_head\"),\n",
    "    scorer=Scorer(customize_metric_funcs={\"accuacy_macro_f1\": accuacy_macro_f1}),\n",
    ")\n",
    "tasks.append(master_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:34:52,507][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n",
      "[2019-05-22 18:34:57,389][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n",
      "[2019-05-22 18:34:57,392][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n",
      "[2019-05-22 18:34:57,399][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n",
      "[2019-05-22 18:34:57,405][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n",
      "[2019-05-22 18:34:58,750][INFO] emmental.model:44 - Created emmental model SuperGLUE_single_task that contains task {'CB_slice_pred_slice_base', 'CB_slice_pred_slice_base_1', 'CB_slice_ind_slice_base', 'CB', 'CB_slice_ind_slice_base_1'}.\n",
      "[2019-05-22 18:34:58,751][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n",
      "[2019-05-22 18:34:58,759][INFO] emmental.logging.logging_manager:33 - Evaluating every 1 epoch.\n",
      "[2019-05-22 18:34:58,760][INFO] emmental.logging.logging_manager:43 - Checkpointing every 1 epoch.\n",
      "[2019-05-22 18:34:58,761][INFO] emmental.logging.checkpointer:42 - Save checkpoints at logs/2019_05_22/18_34_00 every 1 epoch\n",
      "[2019-05-22 18:34:58,762][INFO] emmental.logging.checkpointer:73 - No checkpoints saved before 0 epoch.\n",
      "[2019-05-22 18:34:58,813][INFO] root:123 - Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
      "[2019-05-22 18:34:58,860][INFO] root:123 - Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n",
      "[2019-05-22 18:34:58,997][INFO] emmental.learner:152 - Warmup 126 batchs.\n",
      "[2019-05-22 18:34:59,001][INFO] emmental.learner:298 - Start learning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536bc27904194486be408e3079f41ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[2019-05-22 18:35:50,334][INFO] emmental.logging.checkpointer:93 - checkpoint_runway condition has been met. Start checkpoining.\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type FeatureConcateModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MasterModule. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "[2019-05-22 18:36:05,073][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 1.0 epoch at logs/2019_05_22/18_34_00/checkpoint_1.0.pth.\n",
      "[2019-05-22 18:36:22,734][INFO] emmental.logging.checkpointer:119 - Save best model of metric CB/SuperGLUE/val/accuacy_macro_f1 at logs/2019_05_22/18_34_00/best_model_CB_SuperGLUE_val_accuacy_macro_f1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bc6ef4ca4843e88996f2eebc0839f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:37:43,207][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 2.0 epoch at logs/2019_05_22/18_34_00/checkpoint_2.0.pth.\n",
      "[2019-05-22 18:37:55,548][INFO] emmental.logging.checkpointer:119 - Save best model of metric CB/SuperGLUE/val/accuacy_macro_f1 at logs/2019_05_22/18_34_00/best_model_CB_SuperGLUE_val_accuacy_macro_f1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d84d6235d34f1ca6cae67e749a7c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:38:57,869][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 3.0 epoch at logs/2019_05_22/18_34_00/checkpoint_3.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2e05ba1c664e74b03136ac20166f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:40:00,796][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 4.0 epoch at logs/2019_05_22/18_34_00/checkpoint_4.0.pth.\n",
      "[2019-05-22 18:40:11,357][INFO] emmental.logging.checkpointer:119 - Save best model of metric CB/SuperGLUE/val/accuacy_macro_f1 at logs/2019_05_22/18_34_00/best_model_CB_SuperGLUE_val_accuacy_macro_f1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e29fb59795486d80fd0dae1234864e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:41:15,289][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 5.0 epoch at logs/2019_05_22/18_34_00/checkpoint_5.0.pth.\n",
      "[2019-05-22 18:41:27,302][INFO] emmental.logging.checkpointer:119 - Save best model of metric CB/SuperGLUE/val/accuacy_macro_f1 at logs/2019_05_22/18_34_00/best_model_CB_SuperGLUE_val_accuacy_macro_f1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d45fcd2c955468babc745c79a4e0c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:42:29,856][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 6.0 epoch at logs/2019_05_22/18_34_00/checkpoint_6.0.pth.\n",
      "[2019-05-22 18:42:42,091][INFO] emmental.logging.checkpointer:119 - Save best model of metric CB/SuperGLUE/val/accuacy_macro_f1 at logs/2019_05_22/18_34_00/best_model_CB_SuperGLUE_val_accuacy_macro_f1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852a6e0a1dff4d3aad54d572f4b1c295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:43:45,416][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 7.0 epoch at logs/2019_05_22/18_34_00/checkpoint_7.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f54f9e5195a49dd8dd730f5cf711a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:44:49,450][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 8.0 epoch at logs/2019_05_22/18_34_00/checkpoint_8.0.pth.\n",
      "[2019-05-22 18:45:01,627][INFO] emmental.logging.checkpointer:119 - Save best model of metric CB/SuperGLUE/val/accuacy_macro_f1 at logs/2019_05_22/18_34_00/best_model_CB_SuperGLUE_val_accuacy_macro_f1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258be86eda3e44b3ab3da81093ed349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:46:04,702][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 9.0 epoch at logs/2019_05_22/18_34_00/checkpoint_9.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d4dae2055d4b91aab448c18dac23de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9:', max=63, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:47:07,377][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 10.0 epoch at logs/2019_05_22/18_34_00/checkpoint_10.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef9ae5cab454b01974570abda2284d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:48:10,196][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 11.0 epoch at logs/2019_05_22/18_34_00/checkpoint_11.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108eefb2b0f14e478e3907feb442c735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:49:13,194][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 12.0 epoch at logs/2019_05_22/18_34_00/checkpoint_12.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b720c522ed4e63989f6832e3effb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:50:16,216][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 13.0 epoch at logs/2019_05_22/18_34_00/checkpoint_13.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f339eee435470f8062cec98f80b2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:51:19,350][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 14.0 epoch at logs/2019_05_22/18_34_00/checkpoint_14.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d1b685df294257b4a531eefde79e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:52:22,561][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 15.0 epoch at logs/2019_05_22/18_34_00/checkpoint_15.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1932fca24b41d3b3b123c25ca41952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:53:25,481][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 16.0 epoch at logs/2019_05_22/18_34_00/checkpoint_16.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e85bcb2b324dfcb712c1adc0d3d0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:54:28,017][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 17.0 epoch at logs/2019_05_22/18_34_00/checkpoint_17.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b1b9d35d284e8981419236ecb43611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:55:30,226][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 18.0 epoch at logs/2019_05_22/18_34_00/checkpoint_18.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308d17c712774978a62adb991bcc912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:56:33,205][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 19.0 epoch at logs/2019_05_22/18_34_00/checkpoint_19.0.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c78a6b764b49218dfbdb0b778b794b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 19:', max=63, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:57:35,863][INFO] emmental.logging.checkpointer:103 - Save checkpoint of 20.0 epoch at logs/2019_05_22/18_34_00/checkpoint_20.0.pth.\n",
      "[2019-05-22 18:57:35,917][INFO] emmental.logging.checkpointer:149 - Clear all immediate checkpoints.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-22 18:57:43,002][INFO] emmental.logging.checkpointer:189 - Loading the best model from logs/2019_05_22/18_34_00/best_model_CB_SuperGLUE_val_accuacy_macro_f1.pth.\n",
      "[2019-05-22 18:57:45,314][INFO] emmental.model:58 - Moving model to GPU (cuda:1).\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name=\"SuperGLUE_single_task\", tasks=tasks)\n",
    "emmental_learner = EmmentalLearner()\n",
    "emmental_learner.learn(mtl_model, dataloaders.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CB_slice_ind_slice_base/SuperGLUE/val/accuracy': 1.0,\n",
       " 'CB_slice_pred_slice_base/SuperGLUE/val/macro_f1': 0.9237290159275974,\n",
       " 'CB_slice_pred_slice_base/SuperGLUE/val/accuracy': 0.9285714285714286,\n",
       " 'CB_slice_pred_slice_base/SuperGLUE/val/accuacy_macro_f1': 0.926150222249513,\n",
       " 'CB_slice_ind_slice_base_1/SuperGLUE/val/accuracy': 1.0,\n",
       " 'CB_slice_pred_slice_base_1/SuperGLUE/val/macro_f1': 0.8917213078192603,\n",
       " 'CB_slice_pred_slice_base_1/SuperGLUE/val/accuracy': 0.9107142857142857,\n",
       " 'CB_slice_pred_slice_base_1/SuperGLUE/val/accuacy_macro_f1': 0.9012177967667729,\n",
       " 'CB/SuperGLUE/val/macro_f1': 0.9237290159275974,\n",
       " 'CB/SuperGLUE/val/accuracy': 0.9285714285714286,\n",
       " 'CB/SuperGLUE/val/accuacy_macro_f1': 0.926150222249513}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
