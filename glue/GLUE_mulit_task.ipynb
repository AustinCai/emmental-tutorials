{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.data import EmmentalDataLoader, EmmentalDataset\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from modules.classification_module import ClassificationModule\n",
    "from modules.regression_module import RegressionModule\n",
    "from preprocessor import preprocessor\n",
    "from task_config import LABEL_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAMES = [\"RTE\", \"STS-B\"]\n",
    "DATA_DIR = \"data\"\n",
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:11,024][INFO] emmental.meta:95 - Setting logging directory to: logs/2019_04_23/20_51_10\n",
      "[2019-04-23 20:51:11,040][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch1/senwu/mmtl/emmental/src/emmental/emmental-default-config.yaml.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev/test dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c9fa1afc564c28ace77467ec294f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2490), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:13,184][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-23 20:51:18,472][INFO] __main__:24 - Loaded train for RTE.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e557fc7a9143c48b70ba95a92292d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=277), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:18,789][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-23 20:51:19,399][INFO] __main__:24 - Loaded dev for RTE.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f000d84645ab479d8f0ed0d4275db5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:19,946][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-23 20:51:25,986][INFO] __main__:24 - Loaded test for RTE.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1823cc79c0f41919d8bd514aab7c58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:26,443][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-23 20:51:31,139][INFO] __main__:24 - Loaded train for STS-B.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a341a39e761b4736bb0b0fa6d02dafa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:31,506][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-23 20:51:32,881][INFO] __main__:24 - Loaded dev for STS-B.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93dfa44d666c472b88954b8c6c39f7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1379), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:33,212][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-23 20:51:34,532][INFO] __main__:24 - Loaded test for STS-B.\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "for task_name in TASK_NAMES:\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        bert_token_ids, bert_token_segments, bert_token_masks, labels = preprocessor(\n",
    "            data_dir=DATA_DIR,\n",
    "            task_name=task_name,\n",
    "            split=split,\n",
    "            bert_model_name=BERT_MODEL_NAME,\n",
    "            max_data_samples=None,\n",
    "            max_sequence_length=200,\n",
    "        )\n",
    "        X_dict = {\n",
    "            \"token_ids\": bert_token_ids,\n",
    "            \"token_segments\": bert_token_segments,\n",
    "            \"token_masks\": bert_token_masks,\n",
    "        }\n",
    "        Y_dict = {\"labels\": labels}\n",
    "\n",
    "        if task_name not in datasets: datasets[task_name] = {}\n",
    "        \n",
    "        datasets[task_name][split] = EmmentalDataset(name=\"GLUE\", X_dict=X_dict, Y_dict=Y_dict)\n",
    "\n",
    "        logger.info(f\"Loaded {split} for {task_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:34,575][INFO] __main__:14 - Built dataloader for RTE train set.\n",
      "[2019-04-23 20:51:34,576][INFO] __main__:14 - Built dataloader for RTE dev set.\n",
      "[2019-04-23 20:51:34,577][INFO] __main__:14 - Built dataloader for RTE test set.\n",
      "[2019-04-23 20:51:34,578][INFO] __main__:14 - Built dataloader for STS-B train set.\n",
      "[2019-04-23 20:51:34,580][INFO] __main__:14 - Built dataloader for STS-B dev set.\n",
      "[2019-04-23 20:51:34,581][INFO] __main__:14 - Built dataloader for STS-B test set.\n"
     ]
    }
   ],
   "source": [
    "dataloaders = []\n",
    "\n",
    "for task_name in TASK_NAMES:\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        dataloaders.append(\n",
    "            EmmentalDataLoader(\n",
    "                task_name=task_name,\n",
    "                dataset=datasets[task_name][split],\n",
    "                label_name=\"labels\",\n",
    "                split=split,\n",
    "                batch_size=BATCH_SIZE,\n",
    "            )\n",
    "        )\n",
    "        logger.info(f\"Built dataloader for {task_name} {split} set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(immediate_ouput, Y):\n",
    "    mse = MSELoss()\n",
    "    return mse(immediate_ouput[-1][0].view(-1), Y.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(immediate_ouput, Y):\n",
    "    return F.cross_entropy(immediate_ouput[-1][0], Y.view(-1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(immediate_ouput):\n",
    "    return immediate_ouput[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:51:34,996][INFO] pytorch_pretrained_bert.modeling:564 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "[2019-04-23 20:51:34,998][INFO] pytorch_pretrained_bert.modeling:572 - extracting archive file ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpvn8ltbn8\n",
      "[2019-04-23 20:51:40,849][INFO] pytorch_pretrained_bert.modeling:579 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-04-23 20:51:54,876][INFO] emmental.task:34 - Created task: RTE\n",
      "[2019-04-23 20:51:55,149][INFO] pytorch_pretrained_bert.modeling:564 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "[2019-04-23 20:51:55,151][INFO] pytorch_pretrained_bert.modeling:572 - extracting archive file ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpr569k111\n",
      "[2019-04-23 20:52:00,991][INFO] pytorch_pretrained_bert.modeling:579 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-04-23 20:52:12,776][INFO] emmental.task:34 - Created task: STS-B\n"
     ]
    }
   ],
   "source": [
    "BERT_OUTPUT_DIM = 768 if \"uncased\" in BERT_MODEL_NAME else 1024\n",
    "\n",
    "TASK_CARDINALITY = len(LABEL_MAPPING[\"RTE\"].keys()) if LABEL_MAPPING[\"RTE\"] is not None else 1\n",
    "RTE_task = EmmentalTask(\n",
    "    name=\"RTE\",\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "            \"classification_module\": ClassificationModule(BERT_OUTPUT_DIM, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\"module\": \"bert_module\", \"inputs\": [(0, 'token_ids'), (0, 'token_segments')]},\n",
    "        {\"module\": \"classification_module\", \"inputs\": [(1, 1)]},\n",
    "    ],\n",
    "    loss_func=ce_loss,\n",
    "    output_func=output,\n",
    "    scorer=Scorer(metrics=['accuracy']),\n",
    ")\n",
    "\n",
    "STSB_task = EmmentalTask(\n",
    "    name=\"STS-B\",\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "            \"regression_module\": RegressionModule(BERT_OUTPUT_DIM),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\"module\": \"bert_module\", \"inputs\": [(0, 'token_ids'), (0, 'token_segments')]},\n",
    "        {\"module\": \"regression_module\", \"inputs\": [(1, 1)]},\n",
    "    ],\n",
    "    loss_func=mse_loss,\n",
    "    output_func=output,\n",
    "    scorer=Scorer(metrics=['pearson_spearman']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:52:12,835][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "Meta.update_config(\n",
    "    config={\n",
    "        \"meta_config\": {\"device\": 1},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 3,\n",
    "            \"valid_split\": \"dev\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 5e-5},\n",
    "            \"lr_scheduler_config\": {\"warmup_steps\": 100, \"warmup_unit\": \"batch\", \"lr_scheduler\":\"linear\"},\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"evaluation_freq\": 20,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": f\"RTE/GLUE/train/accuracy\",\n",
    "                \"checkpoint_freq\": 10,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:52:12,874][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-23 20:52:17,756][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-23 20:52:17,762][INFO] emmental.model:44 - Created emmental model GLUE_multi_task that contains task {'RTE', 'STS-B'}.\n",
      "[2019-04-23 20:52:17,763][INFO] emmental.model:57 - Moving model to GPU.\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name = 'GLUE_multi_task', tasks=[RTE_task, STSB_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:52:17,847][INFO] emmental.logging.logging_manager:33 - Evaluating every 20 batch.\n",
      "[2019-04-23 20:52:17,848][INFO] emmental.logging.logging_manager:40 - Checkpointing every 200 batch.\n",
      "[2019-04-23 20:52:17,884][INFO] emmental.logging.checkpointer:41 - Save checkpoints at logs/2019_04_23/20_51_10 every 200 batch\n",
      "[2019-04-23 20:52:17,885][INFO] emmental.logging.checkpointer:65 - No checkpoints saved before 0 batch.\n",
      "[2019-04-23 20:52:17,890][INFO] emmental.learner:249 - Start learning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d0ed8f9f4c4559978b54229a1cfdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=516), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 20:57:55,092][INFO] emmental.logging.checkpointer:87 - Save checkpoint of 200 batch at logs/2019_04_23/20_51_10/checkpoint_200.pth.\n",
      "[2019-04-23 21:03:32,947][INFO] emmental.logging.checkpointer:87 - Save checkpoint of 400 batch at logs/2019_04_23/20_51_10/checkpoint_400.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95aac4b60861424f9f241c264eede017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=516), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 21:09:11,176][INFO] emmental.logging.checkpointer:87 - Save checkpoint of 600 batch at logs/2019_04_23/20_51_10/checkpoint_600.pth.\n",
      "[2019-04-23 21:14:49,036][INFO] emmental.logging.checkpointer:87 - Save checkpoint of 800 batch at logs/2019_04_23/20_51_10/checkpoint_800.pth.\n",
      "[2019-04-23 21:20:26,628][INFO] emmental.logging.checkpointer:87 - Save checkpoint of 1000 batch at logs/2019_04_23/20_51_10/checkpoint_1000.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2596326c1f0484bb34c475881817d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=516), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-23 21:26:03,907][INFO] emmental.logging.checkpointer:87 - Save checkpoint of 1200 batch at logs/2019_04_23/20_51_10/checkpoint_1200.pth.\n",
      "[2019-04-23 21:31:40,926][INFO] emmental.logging.checkpointer:87 - Save checkpoint of 1400 batch at logs/2019_04_23/20_51_10/checkpoint_1400.pth.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emmental_learner.learn(mtl_model, dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/stats.py:3038: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/numpy/lib/function_base.py:2530: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/numpy/lib/function_base.py:2531: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'RTE/GLUE/train/accuracy': 0.8618473895582329,\n",
       " 'RTE/GLUE/dev/accuracy': 0.6173285198555957,\n",
       " 'RTE/GLUE/test/accuracy': 0.0,\n",
       " 'STS-B/GLUE/train/pearson_correlation': 0.9574412,\n",
       " 'STS-B/GLUE/train/pearson_pvalue': 0.0,\n",
       " 'STS-B/GLUE/train/spearman_correlation': 0.9526191808218984,\n",
       " 'STS-B/GLUE/train/spearman_pvalue': 0.0,\n",
       " 'STS-B/GLUE/train/pearson_spearman': 0.9550301957843318,\n",
       " 'STS-B/GLUE/dev/pearson_correlation': 0.87345105,\n",
       " 'STS-B/GLUE/dev/pearson_pvalue': 0.0,\n",
       " 'STS-B/GLUE/dev/spearman_correlation': 0.8707788884160069,\n",
       " 'STS-B/GLUE/dev/spearman_pvalue': 0.0,\n",
       " 'STS-B/GLUE/dev/pearson_spearman': 0.8721149712561145,\n",
       " 'STS-B/GLUE/test/pearson_correlation': 0.0,\n",
       " 'STS-B/GLUE/test/pearson_pvalue': 1.0,\n",
       " 'STS-B/GLUE/test/spearman_correlation': 0.0,\n",
       " 'STS-B/GLUE/test/spearman_pvalue': nan,\n",
       " 'STS-B/GLUE/test/pearson_spearman': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
