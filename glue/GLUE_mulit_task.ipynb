{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.data import EmmentalDataLoader, EmmentalDataset\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from modules.classification_module import ClassificationModule\n",
    "from modules.regression_module import RegressionModule\n",
    "from preprocessor import preprocessor\n",
    "from task_config import LABEL_MAPPING, GLUE_TASK_NAMES\n",
    "from glue_tasks import get_gule_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK_NAMES = [\"RTE\", \"STS-B\"]\n",
    "DATA_DIR = \"data\"\n",
    "BERT_MODEL_NAME = \"bert-base-uncased\"\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:28,372][INFO] emmental.meta:95 - Setting logging directory to: logs/2019_04_25/17_01_28\n",
      "[2019-04-25 17:01:28,388][INFO] emmental.meta:56 - Loading Emmental default config from /dfs/scratch1/senwu/mmtl/emmental/src/emmental/emmental-default-config.yaml.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\"logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract train/dev/test dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7576786cfa024ee7814cda5efda12f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:28,850][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:29,246][INFO] __main__:24 - Loaded train for CoLA.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47a268a099748ddb9a3188bf3fd4ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:29,562][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:29,922][INFO] __main__:24 - Loaded dev for CoLA.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e36d4ed8e64d46a9003718906e3831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:30,260][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:30,611][INFO] __main__:24 - Loaded test for CoLA.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f021a1b0d9f4ed1ac47a8bd6b3371b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:46,461][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:47,681][INFO] __main__:24 - Loaded train for MNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fde898b5d664c6cb487d34223478c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:48,484][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:49,675][INFO] __main__:24 - Loaded dev for MNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c088d4d03f1542809fe472e4fce97a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:50,360][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:51,577][INFO] __main__:24 - Loaded test for MNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ce86d834c345dfa5443fc8b3151fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:51,964][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:53,618][INFO] __main__:24 - Loaded train for MRPC.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4063617c29340a2887416b3b0116450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=408), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:53,937][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:54,650][INFO] __main__:24 - Loaded dev for MRPC.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cac6895b6d24de2a9e08317db76e791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:54,990][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:01:56,631][INFO] __main__:24 - Loaded test for MRPC.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422d0995f0fd4bd084e67246fefabc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:01:59,088][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:00,635][INFO] __main__:24 - Loaded train for QNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b73b21ab204535bdc30d08d43e5a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:01,062][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:02,538][INFO] __main__:24 - Loaded dev for QNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f0e42446de4048b1cc6db8937c239d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:02,955][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:05,201][INFO] __main__:24 - Loaded test for QNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f1f9495b9f492faf4c7ca08e5df282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:10,967][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:11,871][INFO] __main__:24 - Loaded train for QQP.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ee8138e32f41d89f22e07e6b49e3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:12,775][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:13,680][INFO] __main__:24 - Loaded dev for QQP.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc28e4024974ac29d79051bcb665a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:19,625][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:20,529][INFO] __main__:24 - Loaded test for QQP.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc26ae1b56fc4996b5e92960fa144c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:20,886][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:23,102][INFO] __main__:24 - Loaded train for RTE.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cc1cd374114d90ba619d2b10d6afa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=277), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:23,410][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:24,027][INFO] __main__:24 - Loaded dev for RTE.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a817d5bfd245d98c01f07edf2c1b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:24,401][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:25,946][INFO] __main__:24 - Loaded test for RTE.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49da138fa364f01b4ccf18d4fbfd814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:45,184][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:45,995][INFO] __main__:24 - Loaded train for SNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2142e0b6ff7c48289be478e37888d402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:46,660][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:47,508][INFO] __main__:24 - Loaded dev for SNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec8fd7df2c74279a3fcba5c1ef39edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:47,885][WARNING] preprocessor:136 - Data column doesn't match, skip...\n",
      "[2019-04-25 17:02:47,891][WARNING] preprocessor:136 - Data column doesn't match, skip...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:48,377][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:49,198][INFO] __main__:24 - Loaded test for SNLI.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f19e1c699024842b688521e3533a327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:50,064][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:50,488][INFO] __main__:24 - Loaded train for SST-2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9701d54c5a4e7facba4fbe8652fb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=872), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:50,805][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:51,493][INFO] __main__:24 - Loaded dev for SST-2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992711ea291940d5b4467d4dfd763f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:02:51,819][INFO] pytorch_pretrained_bert.tokenization:146 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /lfs/local/0/senwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-04-25 17:02:52,583][INFO] __main__:24 - Loaded test for SST-2.\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "for task_name in GLUE_TASK_NAMES:\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        bert_token_ids, bert_token_segments, bert_token_masks, labels = preprocessor(\n",
    "            data_dir=DATA_DIR,\n",
    "            task_name=task_name,\n",
    "            split=split,\n",
    "            bert_model_name=BERT_MODEL_NAME,\n",
    "            max_data_samples=1000,\n",
    "            max_sequence_length=100,\n",
    "        )\n",
    "        X_dict = {\n",
    "            \"token_ids\": bert_token_ids,\n",
    "            \"token_segments\": bert_token_segments,\n",
    "            \"token_masks\": bert_token_masks,\n",
    "        }\n",
    "        Y_dict = {\"labels\": labels}\n",
    "\n",
    "        if task_name not in datasets: datasets[task_name] = {}\n",
    "        \n",
    "        datasets[task_name][split] = EmmentalDataset(name=\"GLUE\", X_dict=X_dict, Y_dict=Y_dict)\n",
    "\n",
    "        logger.info(f\"Loaded {split} for {task_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = []\n",
    "\n",
    "for task_name in GLUE_TASK_NAMES:\n",
    "    for split in [\"train\", \"dev\", \"test\"]:\n",
    "        dataloaders.append(\n",
    "            EmmentalDataLoader(\n",
    "                task_name=task_name,\n",
    "                dataset=datasets[task_name][split],\n",
    "                label_name=\"labels\",\n",
    "                split=split,\n",
    "                batch_size=BATCH_SIZE,\n",
    "            )\n",
    "        )\n",
    "        logger.info(f\"Built dataloader for {task_name} {split} set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:04:35,192][INFO] pytorch_pretrained_bert.modeling:579 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-04-25 17:04:46,583][INFO] emmental.task:34 - Created task: RTE\n",
      "[2019-04-25 17:04:46,854][INFO] pytorch_pretrained_bert.modeling:564 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "[2019-04-25 17:04:46,856][INFO] pytorch_pretrained_bert.modeling:572 - extracting archive file ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpbj5zg3_m\n",
      "[2019-04-25 17:04:52,652][INFO] pytorch_pretrained_bert.modeling:579 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-04-25 17:05:04,380][INFO] emmental.task:34 - Created task: SNLI\n",
      "[2019-04-25 17:05:04,672][INFO] pytorch_pretrained_bert.modeling:564 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "[2019-04-25 17:05:04,675][INFO] pytorch_pretrained_bert.modeling:572 - extracting archive file ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpwavz5lci\n",
      "[2019-04-25 17:05:10,661][INFO] pytorch_pretrained_bert.modeling:579 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-04-25 17:05:22,324][INFO] emmental.task:34 - Created task: SST-2\n",
      "[2019-04-25 17:05:22,635][INFO] pytorch_pretrained_bert.modeling:564 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "[2019-04-25 17:05:22,637][INFO] pytorch_pretrained_bert.modeling:572 - extracting archive file ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmps5okeq6c\n",
      "[2019-04-25 17:05:28,416][INFO] pytorch_pretrained_bert.modeling:579 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-04-25 17:05:40,051][INFO] emmental.task:34 - Created task: STS-B\n",
      "[2019-04-25 17:05:40,322][INFO] pytorch_pretrained_bert.modeling:564 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "[2019-04-25 17:05:40,325][INFO] pytorch_pretrained_bert.modeling:572 - extracting archive file ./cache/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp6iza93a0\n",
      "[2019-04-25 17:05:46,119][INFO] pytorch_pretrained_bert.modeling:579 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-04-25 17:05:57,883][INFO] emmental.task:34 - Created task: WNLI\n"
     ]
    }
   ],
   "source": [
    "tasks = [get_gule_task(task_name, BERT_MODEL_NAME) for task_name in GLUE_TASK_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mse_loss(immediate_ouput, Y):\n",
    "#     mse = MSELoss()\n",
    "#     return mse(immediate_ouput[-1][0].view(-1), Y.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ce_loss(immediate_ouput, Y):\n",
    "#     return F.cross_entropy(immediate_ouput[-1][0], Y.view(-1) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def output(immediate_ouput):\n",
    "#     return immediate_ouput[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT_OUTPUT_DIM = 768 if \"uncased\" in BERT_MODEL_NAME else 1024\n",
    "\n",
    "# TASK_CARDINALITY = len(LABEL_MAPPING[\"RTE\"].keys()) if LABEL_MAPPING[\"RTE\"] is not None else 1\n",
    "# RTE_task = EmmentalTask(\n",
    "#     name=\"RTE\",\n",
    "#     module_pool=nn.ModuleDict(\n",
    "#         {\n",
    "#             \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "#             \"classification_module\": ClassificationModule(BERT_OUTPUT_DIM, TASK_CARDINALITY),\n",
    "#         }\n",
    "#     ),\n",
    "#     task_flow=[\n",
    "#         {\"module\": \"bert_module\", \"inputs\": [(0, 'token_ids'), (0, 'token_segments')]},\n",
    "#         {\"module\": \"classification_module\", \"inputs\": [(1, 1)]},\n",
    "#     ],\n",
    "#     loss_func=ce_loss,\n",
    "#     output_func=output,\n",
    "#     scorer=Scorer(metrics=['accuracy']),\n",
    "# )\n",
    "\n",
    "# STSB_task = EmmentalTask(\n",
    "#     name=\"STS-B\",\n",
    "#     module_pool=nn.ModuleDict(\n",
    "#         {\n",
    "#             \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "#             \"regression_module\": RegressionModule(BERT_OUTPUT_DIM),\n",
    "#         }\n",
    "#     ),\n",
    "#     task_flow=[\n",
    "#         {\"module\": \"bert_module\", \"inputs\": [(0, 'token_ids'), (0, 'token_segments')]},\n",
    "#         {\"module\": \"regression_module\", \"inputs\": [(1, 1)]},\n",
    "#     ],\n",
    "#     loss_func=mse_loss,\n",
    "#     output_func=output,\n",
    "#     scorer=Scorer(metrics=['pearson_spearman']),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:05:58,078][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "Meta.update_config(\n",
    "    config={\n",
    "        \"meta_config\": {\"device\": 0},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 3,\n",
    "            \"valid_split\": \"dev\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 5e-5},\n",
    "            \"lr_scheduler_config\": {\"warmup_steps\": 100, \"warmup_unit\": \"batch\", \"lr_scheduler\":\"linear\"},\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"evaluation_freq\": 100,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": f\"RTE/GLUE/train/accuracy\",\n",
    "                \"checkpoint_freq\": 100000000,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:05:58,112][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:02,994][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,003][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,008][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,013][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,017][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,022][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,027][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,032][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,036][INFO] emmental.model:57 - Moving model to GPU.\n",
      "[2019-04-25 17:06:03,040][INFO] emmental.model:44 - Created emmental model GLUE_multi_task that contains task {'QQP', 'WNLI', 'SST-2', 'MRPC', 'MNLI', 'STS-B', 'SNLI', 'CoLA', 'RTE', 'QNLI'}.\n",
      "[2019-04-25 17:06:03,040][INFO] emmental.model:57 - Moving model to GPU.\n"
     ]
    }
   ],
   "source": [
    "# mtl_model = EmmentalModel(name = 'GLUE_multi_task', tasks=[RTE_task, STSB_task])\n",
    "mtl_model = EmmentalModel(name = 'GLUE_multi_task', tasks=tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmental_learner = EmmentalLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-04-25 17:29:19,145][INFO] emmental.logging.logging_manager:33 - Evaluating every 100 batch.\n",
      "[2019-04-25 17:29:19,146][INFO] emmental.logging.logging_manager:40 - Checkpointing every 10000000000 batch.\n",
      "[2019-04-25 17:29:19,210][INFO] emmental.logging.checkpointer:41 - Save checkpoints at logs/2019_04_25/17_01_28 every 10000000000 batch\n",
      "[2019-04-25 17:29:19,211][INFO] emmental.logging.checkpointer:65 - No checkpoints saved before 0 batch.\n",
      "[2019-04-25 17:29:19,217][INFO] emmental.learner:249 - Start learning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc2ecd142bf448ea09d9f8640349979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=607), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/sklearn/metrics/classification.py:543: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebde4a2d9cec42238f527deb8d251afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=607), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542dcd6d31954fe0a6692d20e5170894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=607), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emmental_learner.learn(mtl_model, dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/stats.py:3038: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/numpy/lib/function_base.py:2530: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/numpy/lib/function_base.py:2531: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/lfs/raiders3/0/senwu/.venv_emmental/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CoLA/GLUE/train/matthews_corrcoef': 0.8037668823449967,\n",
       " 'CoLA/GLUE/dev/matthews_corrcoef': 0.3310809477308711,\n",
       " 'CoLA/GLUE/test/matthews_corrcoef': 0.0,\n",
       " 'MNLI/GLUE/train/accuracy': 0.917,\n",
       " 'MNLI/GLUE/dev/accuracy': 0.616,\n",
       " 'MNLI/GLUE/test/accuracy': 0.0,\n",
       " 'MRPC/GLUE/train/accuracy': 0.968,\n",
       " 'MRPC/GLUE/train/f1': 0.9762611275964392,\n",
       " 'MRPC/GLUE/dev/accuracy': 0.7843137254901961,\n",
       " 'MRPC/GLUE/dev/f1': 0.8508474576271187,\n",
       " 'MRPC/GLUE/test/accuracy': 0.0,\n",
       " 'MRPC/GLUE/test/f1': 0.0,\n",
       " 'QNLI/GLUE/train/accuracy': 0.967,\n",
       " 'QNLI/GLUE/dev/accuracy': 0.677,\n",
       " 'QNLI/GLUE/test/accuracy': 0.0,\n",
       " 'QQP/GLUE/train/accuracy': 0.972,\n",
       " 'QQP/GLUE/train/f1': 0.9615384615384616,\n",
       " 'QQP/GLUE/dev/accuracy': 0.775,\n",
       " 'QQP/GLUE/dev/f1': 0.6853146853146853,\n",
       " 'QQP/GLUE/test/accuracy': 0.0,\n",
       " 'QQP/GLUE/test/f1': 0.0,\n",
       " 'RTE/GLUE/train/accuracy': 0.933,\n",
       " 'RTE/GLUE/dev/accuracy': 0.6570397111913358,\n",
       " 'RTE/GLUE/test/accuracy': 0.0,\n",
       " 'SNLI/GLUE/train/accuracy': 0.935,\n",
       " 'SNLI/GLUE/dev/accuracy': 0.754,\n",
       " 'SNLI/GLUE/test/accuracy': 0.7224448897795591,\n",
       " 'SST-2/GLUE/train/accuracy': 0.994,\n",
       " 'SST-2/GLUE/dev/accuracy': 0.8681192660550459,\n",
       " 'SST-2/GLUE/test/accuracy': 0.0,\n",
       " 'STS-B/GLUE/train/pearson_correlation': 0.94709164,\n",
       " 'STS-B/GLUE/train/pearson_pvalue': 0.0,\n",
       " 'STS-B/GLUE/train/spearman_correlation': 0.9409082509357898,\n",
       " 'STS-B/GLUE/train/spearman_pvalue': 0.0,\n",
       " 'STS-B/GLUE/train/pearson_spearman': 0.9439999449888452,\n",
       " 'STS-B/GLUE/dev/pearson_correlation': 0.74342316,\n",
       " 'STS-B/GLUE/dev/pearson_pvalue': 1.5494856215758428e-176,\n",
       " 'STS-B/GLUE/dev/spearman_correlation': 0.698791408332128,\n",
       " 'STS-B/GLUE/dev/spearman_pvalue': 2.249897939025081e-147,\n",
       " 'STS-B/GLUE/dev/pearson_spearman': 0.7211072861114833,\n",
       " 'STS-B/GLUE/test/pearson_correlation': 0.0,\n",
       " 'STS-B/GLUE/test/pearson_pvalue': 1.0,\n",
       " 'STS-B/GLUE/test/spearman_correlation': 0.0,\n",
       " 'STS-B/GLUE/test/spearman_pvalue': nan,\n",
       " 'STS-B/GLUE/test/pearson_spearman': 0.0,\n",
       " 'WNLI/GLUE/train/accuracy': 0.525984251968504,\n",
       " 'WNLI/GLUE/dev/accuracy': 0.5352112676056338,\n",
       " 'WNLI/GLUE/test/accuracy': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
