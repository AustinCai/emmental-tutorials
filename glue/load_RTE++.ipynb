{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.data import EmmentalDataLoader, EmmentalDataset\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from modules.classification_module import ClassificationModule\n",
    "from preprocessor import preprocessor\n",
    "from task_config import LABEL_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"MNLI\"\n",
    "DATA_DIR = os.environ[\"GLUEDATA\"]\n",
    "BERT_MODEL_NAME = \"bert-large-uncased\"\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:20:26,566][INFO] emmental.meta:95 - Setting logging directory to: logs/RTE_finetune/2019_05_31/07_20_26\n",
      "[2019-05-31 07:20:26,575][INFO] emmental.meta:56 - Loading Emmental default config from /home/hazymturk/vincent/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-05-31 07:20:26,576][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\"logs/RTE_finetune\",\n",
    "    config={\n",
    "        \"meta_config\": {\"seed\": 1},\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": True},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 20,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"lr_scheduler_config\": {\n",
    "                \"lr_scheduler\": \"linear\",  # \"linear\",\n",
    "                \"min_lr\": 1e-7,\n",
    "            },\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"epoch\",\n",
    "            \"evaluation_freq\": 0.2,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": {\"RTE/SuperGLUE/val/accuracy\":\"max\"},\n",
    "                \"checkpoint_freq\": 1,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Emmental task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(task_name, immediate_ouput_dict, Y, active):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(task_name, immediate_ouput_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:20:35,708][INFO] emmental.model:44 - Created emmental model GLUE_single_task that contains task set().\n",
      "[2019-05-31 07:20:35,710][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name=\"GLUE_single_task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:20:42,908][INFO] emmental.model:412 - [GLUE_multi_task] Model loaded from logs/RTE_finetune/2019_05_31/05_38_02/best_model_RTE_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-31 07:20:42,910][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model.load(\n",
    "    \"logs/RTE_finetune/2019_05_31/05_38_02/best_model_RTE_SuperGLUE_val_accuracy.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"RTE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superglue.parse_RTE import get_RTE_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superglue.task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:20:43,886][INFO] pytorch_pretrained_bert.modeling:583 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ./cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "[2019-05-31 07:20:43,888][INFO] pytorch_pretrained_bert.modeling:591 - extracting archive file ./cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmp62cwhxb9\n",
      "[2019-05-31 07:20:54,448][INFO] pytorch_pretrained_bert.modeling:601 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-05-31 07:20:59,222][INFO] emmental.task:34 - Created task: RTE\n"
     ]
    }
   ],
   "source": [
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")\n",
    "\n",
    "emmental_task = EmmentalTask(\n",
    "    name=TASK_NAME,\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "            f\"{TASK_NAME}_pred_head\": nn.Linear(BERT_OUTPUT_DIM, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": \"input\",\n",
    "            \"module\": \"bert_module\",\n",
    "            \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "        },\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [(\"input\", 1)],\n",
    "        },\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, TASK_NAME),\n",
    "    output_func=partial(output, TASK_NAME),\n",
    "    scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:20:59,245][INFO] emmental.model:136 - Task (MNLI) not in the current model, skip...\n"
     ]
    }
   ],
   "source": [
    "mtl_model.remove_task(\"MNLI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:20:59,309][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model.add_task(emmental_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:20:59,335][INFO] superglue.tokenizer:8 - Loading Tokenizer bert-large-uncased\n",
      "[2019-05-31 07:21:00,132][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /home/hazymturk/.cache/torch/pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazymturk/vincent/emmental-tutorials/superglue/data/RTE/train.jsonl\n",
      "{'premise': 'No Weapons of Mass Destruction Found in Iraq Yet.', 'hypothesis': 'Weapons of Mass Destruction Found in Iraq.', 'label': 'not_entailment', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:21:02,437][INFO] superglue.parse_RTE:123 - Loaded train for RTE.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazymturk/vincent/emmental-tutorials/superglue/data/RTE/val.jsonl\n",
      "{'premise': 'Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.', 'hypothesis': 'Christopher Reeve had an accident.', 'label': 'not_entailment', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:21:02,702][INFO] superglue.parse_RTE:123 - Loaded val for RTE.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.environ[\"SUPERGLUEDATA\"]\n",
    "dataloaders = get_RTE_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\"],\n",
    "    max_sequence_length=200,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RTE/SuperGLUE/val/accuracy': 0.8303249097472925}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
