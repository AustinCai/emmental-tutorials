{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import emmental\n",
    "from emmental import Meta\n",
    "from emmental.data import EmmentalDataLoader, EmmentalDataset\n",
    "from emmental.learner import EmmentalLearner\n",
    "from emmental.model import EmmentalModel\n",
    "from emmental.scorer import Scorer\n",
    "from emmental.task import EmmentalTask\n",
    "from modules.bert_module import BertModule\n",
    "from modules.classification_module import ClassificationModule\n",
    "from preprocessor import preprocessor\n",
    "from task_config import LABEL_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"MNLI\"\n",
    "DATA_DIR = os.environ[\"GLUEDATA\"]\n",
    "BERT_MODEL_NAME = \"bert-large-uncased\"\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initalize Emmental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:56:16,973][INFO] emmental.meta:95 - Setting logging directory to: logs/CB_finetune/2019_05_31/07_56_16\n",
      "[2019-05-31 07:56:16,983][INFO] emmental.meta:56 - Loading Emmental default config from /home/hazymturk/vincent/emmental/src/emmental/emmental-default-config.yaml.\n",
      "[2019-05-31 07:56:16,984][INFO] emmental.meta:143 - Updating Emmental config from user provided config.\n"
     ]
    }
   ],
   "source": [
    "emmental.init(\"logs/CB_finetune\",\n",
    "    config={\n",
    "        \"meta_config\": {\"seed\": 1},\n",
    "        \"model_config\": {\"device\": 0, \"dataparallel\": True},\n",
    "        \"learner_config\": {\n",
    "            \"n_epochs\": 10,\n",
    "            \"valid_split\": \"val\",\n",
    "            \"optimizer_config\": {\"optimizer\": \"adam\", \"lr\": 1e-5},\n",
    "            \"lr_scheduler_config\": {\n",
    "                \"lr_scheduler\": \"linear\",  # \"linear\",\n",
    "                \"min_lr\": 1e-7,\n",
    "            },\n",
    "        },\n",
    "        \"logging_config\": {\n",
    "            \"counter_unit\": \"epoch\",\n",
    "            \"evaluation_freq\": 0.5,\n",
    "            \"checkpointing\": True,\n",
    "            \"checkpointer_config\": {\n",
    "                \"checkpoint_metric\": {\"CB/SuperGLUE/val/accuracy\":\"max\"},\n",
    "                \"checkpoint_freq\": 1,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce_loss(task_name, immediate_ouput_dict, Y, active):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.cross_entropy(\n",
    "        immediate_ouput_dict[module_name][0][active], (Y.view(-1) - 1)[active]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(task_name, immediate_ouput_dict):\n",
    "    module_name = f\"{task_name}_pred_head\"\n",
    "    return F.softmax(immediate_ouput_dict[module_name][0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def macro_f1(golds, probs, preds):\n",
    "    return {\"macro_f1\": f1_score(golds, preds, average=\"macro\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:56:24,109][INFO] emmental.model:44 - Created emmental model GLUE_single_task that contains task set().\n",
      "[2019-05-31 07:56:24,110][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model = EmmentalModel(name=\"GLUE_single_task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:56:31,873][INFO] emmental.model:412 - [GLUE_multi_task] Model loaded from logs/CB_finetune/2019_05_31/07_44_08/best_model_CB_SuperGLUE_val_accuracy.pth\n",
      "[2019-05-31 07:56:31,875][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model.load(\n",
    "    \"logs/CB_finetune/2019_05_31/07_44_08/best_model_CB_SuperGLUE_val_accuracy.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"CB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superglue.parse_CB import get_CB_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superglue.task_config import SuperGLUE_LABEL_MAPPING, SuperGLUE_TASK_METRIC_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:56:32,806][INFO] pytorch_pretrained_bert.modeling:583 - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at ./cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "[2019-05-31 07:56:32,808][INFO] pytorch_pretrained_bert.modeling:591 - extracting archive file ./cache/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmpnb2e40x3\n",
      "[2019-05-31 07:56:44,029][INFO] pytorch_pretrained_bert.modeling:601 - Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-05-31 07:56:49,150][INFO] emmental.task:34 - Created task: CB\n"
     ]
    }
   ],
   "source": [
    "BERT_OUTPUT_DIM = 768 if \"base\" in BERT_MODEL_NAME else 1024\n",
    "TASK_CARDINALITY = (\n",
    "    len(SuperGLUE_LABEL_MAPPING[TASK_NAME].keys())\n",
    "    if SuperGLUE_LABEL_MAPPING[TASK_NAME] is not None\n",
    "    else 1\n",
    ")\n",
    "\n",
    "emmental_task = EmmentalTask(\n",
    "    name=TASK_NAME,\n",
    "    module_pool=nn.ModuleDict(\n",
    "        {\n",
    "            \"bert_module\": BertModule(BERT_MODEL_NAME),\n",
    "            f\"{TASK_NAME}_pred_head\": nn.Linear(BERT_OUTPUT_DIM, TASK_CARDINALITY),\n",
    "        }\n",
    "    ),\n",
    "    task_flow=[\n",
    "        {\n",
    "            \"name\": \"input\",\n",
    "            \"module\": \"bert_module\",\n",
    "            \"inputs\": [(\"_input_\", \"token_ids\"), (\"_input_\", \"token_segments\")],\n",
    "        },\n",
    "        {\n",
    "            \"name\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"module\": f\"{TASK_NAME}_pred_head\",\n",
    "            \"inputs\": [(\"input\", 1)],\n",
    "        },\n",
    "    ],\n",
    "    loss_func=partial(ce_loss, TASK_NAME),\n",
    "    output_func=partial(output, TASK_NAME),\n",
    "    scorer=Scorer(metrics=SuperGLUE_TASK_METRIC_MAPPING[TASK_NAME]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:56:49,178][INFO] emmental.model:58 - Moving model to GPU (cuda:0).\n"
     ]
    }
   ],
   "source": [
    "mtl_model.add_task(emmental_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:56:49,201][INFO] superglue.tokenizer:8 - Loading Tokenizer bert-large-uncased\n",
      "[2019-05-31 07:56:50,002][INFO] pytorch_pretrained_bert.tokenization:190 - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /home/hazymturk/.cache/torch/pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazymturk/vincent/emmental-tutorials/superglue/data/CB/train.jsonl\n",
      "{'premise': 'It was a complex language. Not written down but handed down. One might say it was peeled down.', 'hypothesis': 'the language was peeled down', 'label': 'entailment', 'idx': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-05-31 07:56:50,281][INFO] superglue.parse_CB:123 - Loaded train for CB.\n",
      "[2019-05-31 07:56:50,344][INFO] superglue.parse_CB:123 - Loaded val for CB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazymturk/vincent/emmental-tutorials/superglue/data/CB/val.jsonl\n",
      "{'premise': \"Valence the void-brain, Valence the virtuous valet. Why couldn't the figger choose his own portion of titanic anatomy to shaft? Did he think he was helping?\", 'hypothesis': 'Valence was helping', 'label': 'contradiction', 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.environ[\"SUPERGLUEDATA\"]\n",
    "dataloaders = get_CB_dataloaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    task_name=TASK_NAME,\n",
    "    splits=[\"train\", \"val\"],\n",
    "    max_sequence_length=200,\n",
    "    max_data_samples=None,\n",
    "    tokenizer_name=BERT_MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CB/SuperGLUE/val/accuracy': 0.9107142857142857}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtl_model.score(dataloaders[\"val\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
